{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection and Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"forestfires.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0          small  \n",
       "1         0          small  \n",
       "2         0          small  \n",
       "3         0          small  \n",
       "4         0          small  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month            0\n",
       "day              0\n",
       "FFMC             0\n",
       "DMC              0\n",
       "DC               0\n",
       "ISI              0\n",
       "temp             0\n",
       "RH               0\n",
       "wind             0\n",
       "rain             0\n",
       "area             0\n",
       "dayfri           0\n",
       "daymon           0\n",
       "daysat           0\n",
       "daysun           0\n",
       "daythu           0\n",
       "daytue           0\n",
       "daywed           0\n",
       "monthapr         0\n",
       "monthaug         0\n",
       "monthdec         0\n",
       "monthfeb         0\n",
       "monthjan         0\n",
       "monthjul         0\n",
       "monthjun         0\n",
       "monthmar         0\n",
       "monthmay         0\n",
       "monthnov         0\n",
       "monthoct         0\n",
       "monthsep         0\n",
       "size_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130913</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    90.644681  110.872340  547.940039    9.021663   18.889168   44.288201   \n",
       "std      5.520111   64.046482  248.066192    4.559477    5.806625   16.317469   \n",
       "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
       "25%     90.200000   68.600000  437.700000    6.500000   15.500000   33.000000   \n",
       "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
       "75%     92.900000  142.400000  713.900000   10.800000   22.800000   53.000000   \n",
       "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
       "\n",
       "             wind        rain         area      dayfri  ...    monthdec  \\\n",
       "count  517.000000  517.000000   517.000000  517.000000  ...  517.000000   \n",
       "mean     4.017602    0.021663    12.847292    0.164410  ...    0.017408   \n",
       "std      1.791653    0.295959    63.655818    0.371006  ...    0.130913   \n",
       "min      0.400000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "25%      2.700000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "50%      4.000000    0.000000     0.520000    0.000000  ...    0.000000   \n",
       "75%      4.900000    0.000000     6.570000    0.000000  ...    0.000000   \n",
       "max      9.400000    6.400000  1090.840000    1.000000  ...    1.000000   \n",
       "\n",
       "         monthfeb    monthjan    monthjul    monthjun    monthmar    monthmay  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.038685    0.003868    0.061896    0.032882    0.104449    0.003868   \n",
       "std      0.193029    0.062137    0.241199    0.178500    0.306138    0.062137   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         monthnov    monthoct    monthsep  \n",
       "count  517.000000  517.000000  517.000000  \n",
       "mean     0.001934    0.029014    0.332689  \n",
       "std      0.043980    0.168007    0.471632  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#df['size_category'].value_counts().plot.pie()\n",
    "#plt.show()\n",
    "#print(df['size_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "#sns.pairplot(df,hue='size_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "      <td>144</td>\n",
       "      <td>42</td>\n",
       "      <td>85</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>156</td>\n",
       "      <td>42</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>68</td>\n",
       "      <td>30</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>172</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>123</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>116</td>\n",
       "      <td>53</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>168</td>\n",
       "      <td>122</td>\n",
       "      <td>80</td>\n",
       "      <td>156</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  day  FFMC  DMC   DC  ISI  temp  RH  wind  rain  ...  monthdec  \\\n",
       "0        7    0    28   37   41   29    12  34    14     0  ...         0   \n",
       "1       10    5    56   49  144   42    85  16     1     0  ...         0   \n",
       "2       10    2    56   56  156   42    55  16     2     0  ...         0   \n",
       "3        7    0    67   48   33   64    13  72     8     1  ...         0   \n",
       "4        7    3    46   66   46   68    30  73     3     0  ...         0   \n",
       "..     ...  ...   ...  ...  ...  ...   ...  ..   ...   ...  ...       ...   \n",
       "512      1    3     9   71  141    7   172  15     5     0  ...         0   \n",
       "513      1    3     9   71  141    7   123  54    12     0  ...         0   \n",
       "514      1    3     9   71  141    7   116  53    14     0  ...         0   \n",
       "515      1    2    92  168  122   80   156  25     8     0  ...         0   \n",
       "516      9    5     7    2   48    4    34  14     9     0  ...         0   \n",
       "\n",
       "     monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
       "0           0         0         0         0         1         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         1         0         0   \n",
       "4           0         0         0         0         1         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         1   \n",
       "\n",
       "     monthoct  monthsep  \n",
       "0           0         0  \n",
       "1           1         0  \n",
       "2           1         0  \n",
       "3           0         0  \n",
       "4           0         0  \n",
       "..        ...       ...  \n",
       "512         0         0  \n",
       "513         0         0  \n",
       "514         0         0  \n",
       "515         0         0  \n",
       "516         0         0  \n",
       "\n",
       "[517 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder_x=LabelEncoder()\n",
    "x=x.apply(LabelEncoder().fit_transform)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     size_category\n",
       "0                1\n",
       "1                1\n",
       "2                1\n",
       "3                1\n",
       "4                1\n",
       "..             ...\n",
       "512              0\n",
       "513              0\n",
       "514              0\n",
       "515              1\n",
       "516              1\n",
       "\n",
       "[517 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame(y)\n",
    "\n",
    "label_encoder_y = LabelEncoder()\n",
    "y = y.apply(LabelEncoder().fit_transform)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=30,  kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8,  kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1,  kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 0.6251 - accuracy: 0.8410 - val_loss: 0.5169 - val_accuracy: 0.7836\n",
      "Epoch 2/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.9249 - val_loss: 0.2307 - val_accuracy: 0.9357\n",
      "Epoch 3/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1317 - accuracy: 0.9682 - val_loss: 0.1714 - val_accuracy: 0.9474\n",
      "Epoch 4/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0972 - accuracy: 0.9711 - val_loss: 0.1562 - val_accuracy: 0.9415\n",
      "Epoch 5/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.9653 - val_loss: 0.1601 - val_accuracy: 0.9474\n",
      "Epoch 6/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9711 - val_loss: 0.1486 - val_accuracy: 0.9415\n",
      "Epoch 7/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9798 - val_loss: 0.1387 - val_accuracy: 0.9532\n",
      "Epoch 8/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9769 - val_loss: 0.1523 - val_accuracy: 0.9415\n",
      "Epoch 9/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9798 - val_loss: 0.1684 - val_accuracy: 0.9240\n",
      "Epoch 10/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9798 - val_loss: 0.1273 - val_accuracy: 0.9474\n",
      "Epoch 11/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9798 - val_loss: 0.1492 - val_accuracy: 0.9357\n",
      "Epoch 12/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9827 - val_loss: 0.1280 - val_accuracy: 0.9474\n",
      "Epoch 13/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9682 - val_loss: 0.1191 - val_accuracy: 0.9474\n",
      "Epoch 14/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9798 - val_loss: 0.1347 - val_accuracy: 0.9474\n",
      "Epoch 15/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9769 - val_loss: 0.1260 - val_accuracy: 0.9474\n",
      "Epoch 16/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9827 - val_loss: 0.1171 - val_accuracy: 0.9474\n",
      "Epoch 17/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9798 - val_loss: 0.1323 - val_accuracy: 0.9474\n",
      "Epoch 18/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9798 - val_loss: 0.1858 - val_accuracy: 0.9240\n",
      "Epoch 19/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9827 - val_loss: 0.1192 - val_accuracy: 0.9415\n",
      "Epoch 20/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9769 - val_loss: 0.2692 - val_accuracy: 0.8830\n",
      "Epoch 21/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9711 - val_loss: 0.1654 - val_accuracy: 0.9298\n",
      "Epoch 22/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9827 - val_loss: 0.1362 - val_accuracy: 0.9415\n",
      "Epoch 23/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9798 - val_loss: 0.1561 - val_accuracy: 0.9357\n",
      "Epoch 24/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9827 - val_loss: 0.1592 - val_accuracy: 0.9298\n",
      "Epoch 25/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9798 - val_loss: 0.1167 - val_accuracy: 0.9298\n",
      "Epoch 26/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9740 - val_loss: 0.1979 - val_accuracy: 0.9123\n",
      "Epoch 27/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9798 - val_loss: 0.2111 - val_accuracy: 0.9123\n",
      "Epoch 28/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9798 - val_loss: 0.1746 - val_accuracy: 0.9298\n",
      "Epoch 29/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 0.9884 - val_loss: 0.2319 - val_accuracy: 0.9123\n",
      "Epoch 30/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9855 - val_loss: 0.1407 - val_accuracy: 0.9357\n",
      "Epoch 31/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9769 - val_loss: 0.1875 - val_accuracy: 0.9298\n",
      "Epoch 32/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.9827 - val_loss: 0.1707 - val_accuracy: 0.9357\n",
      "Epoch 33/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9827 - val_loss: 0.1611 - val_accuracy: 0.9357\n",
      "Epoch 34/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.9884 - val_loss: 0.2391 - val_accuracy: 0.9181\n",
      "Epoch 35/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9798 - val_loss: 0.2003 - val_accuracy: 0.9298\n",
      "Epoch 36/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9855 - val_loss: 0.2279 - val_accuracy: 0.9181\n",
      "Epoch 37/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9769 - val_loss: 0.1831 - val_accuracy: 0.9357\n",
      "Epoch 38/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 0.9884 - val_loss: 0.2056 - val_accuracy: 0.9298\n",
      "Epoch 39/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9855 - val_loss: 0.1813 - val_accuracy: 0.9298\n",
      "Epoch 40/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.9884 - val_loss: 0.1952 - val_accuracy: 0.9298\n",
      "Epoch 41/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 0.9942 - val_loss: 0.4795 - val_accuracy: 0.9006\n",
      "Epoch 42/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9855 - val_loss: 0.2584 - val_accuracy: 0.9298\n",
      "Epoch 43/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9827 - val_loss: 0.1944 - val_accuracy: 0.9357\n",
      "Epoch 44/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9884 - val_loss: 0.1567 - val_accuracy: 0.9240\n",
      "Epoch 45/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9913 - val_loss: 0.1661 - val_accuracy: 0.9298\n",
      "Epoch 46/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9827 - val_loss: 0.1729 - val_accuracy: 0.9298\n",
      "Epoch 47/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 0.2731 - val_accuracy: 0.9298\n",
      "Epoch 48/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9855 - val_loss: 0.3563 - val_accuracy: 0.9123\n",
      "Epoch 49/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9913 - val_loss: 0.1856 - val_accuracy: 0.9415\n",
      "Epoch 50/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9884 - val_loss: 0.2104 - val_accuracy: 0.9415\n",
      "Epoch 51/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9855 - val_loss: 0.1715 - val_accuracy: 0.9240\n",
      "Epoch 52/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.9942 - val_loss: 0.2716 - val_accuracy: 0.9298\n",
      "Epoch 53/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.2084 - val_accuracy: 0.9415\n",
      "Epoch 54/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.9913 - val_loss: 0.1929 - val_accuracy: 0.9415\n",
      "Epoch 55/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 0.9913 - val_loss: 0.2412 - val_accuracy: 0.9298\n",
      "Epoch 56/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.9913 - val_loss: 0.1829 - val_accuracy: 0.9298\n",
      "Epoch 57/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.9971 - val_loss: 0.3212 - val_accuracy: 0.9240\n",
      "Epoch 58/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9884 - val_loss: 0.2347 - val_accuracy: 0.9298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9884 - val_loss: 0.3337 - val_accuracy: 0.9240\n",
      "Epoch 60/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 0.2578 - val_accuracy: 0.9298\n",
      "Epoch 61/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9913 - val_loss: 0.2486 - val_accuracy: 0.9298\n",
      "Epoch 62/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.1924 - val_accuracy: 0.9357\n",
      "Epoch 63/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 0.9942 - val_loss: 0.3209 - val_accuracy: 0.9298\n",
      "Epoch 64/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.2064 - val_accuracy: 0.9415\n",
      "Epoch 65/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9913 - val_loss: 0.2296 - val_accuracy: 0.9415\n",
      "Epoch 66/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 0.3075 - val_accuracy: 0.9240\n",
      "Epoch 67/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.9971 - val_loss: 0.3704 - val_accuracy: 0.9181\n",
      "Epoch 68/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9942 - val_loss: 0.2757 - val_accuracy: 0.9298\n",
      "Epoch 69/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9913 - val_loss: 0.2307 - val_accuracy: 0.9415\n",
      "Epoch 70/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9913 - val_loss: 0.2336 - val_accuracy: 0.9415\n",
      "Epoch 71/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.9913 - val_loss: 0.2567 - val_accuracy: 0.9298\n",
      "Epoch 72/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 0.2576 - val_accuracy: 0.9298\n",
      "Epoch 73/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.2638 - val_accuracy: 0.9298\n",
      "Epoch 74/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9884 - val_loss: 0.2537 - val_accuracy: 0.9357\n",
      "Epoch 75/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.2911 - val_accuracy: 0.9240\n",
      "Epoch 76/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9884 - val_loss: 0.2150 - val_accuracy: 0.9357\n",
      "Epoch 77/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 0.9913 - val_loss: 0.2924 - val_accuracy: 0.9240\n",
      "Epoch 78/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.3914 - val_accuracy: 0.9181\n",
      "Epoch 79/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9913 - val_loss: 0.2637 - val_accuracy: 0.9298\n",
      "Epoch 80/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9884 - val_loss: 0.2212 - val_accuracy: 0.9415\n",
      "Epoch 81/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9971 - val_loss: 0.2828 - val_accuracy: 0.9298\n",
      "Epoch 82/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.2411 - val_accuracy: 0.9415\n",
      "Epoch 83/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9827 - val_loss: 0.2109 - val_accuracy: 0.9298\n",
      "Epoch 84/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9884 - val_loss: 0.2510 - val_accuracy: 0.9357\n",
      "Epoch 85/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.9942 - val_loss: 0.2872 - val_accuracy: 0.9298\n",
      "Epoch 86/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9971 - val_loss: 0.3704 - val_accuracy: 0.9240\n",
      "Epoch 87/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.9971 - val_loss: 0.2398 - val_accuracy: 0.9415\n",
      "Epoch 88/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9913 - val_loss: 0.2173 - val_accuracy: 0.9298\n",
      "Epoch 89/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 0.2578 - val_accuracy: 0.9357\n",
      "Epoch 90/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.3058 - val_accuracy: 0.9240\n",
      "Epoch 91/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 0.9913 - val_loss: 0.2128 - val_accuracy: 0.9240\n",
      "Epoch 92/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.9942 - val_loss: 0.2802 - val_accuracy: 0.9298\n",
      "Epoch 93/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.2941 - val_accuracy: 0.9298\n",
      "Epoch 94/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9855 - val_loss: 0.2708 - val_accuracy: 0.9357\n",
      "Epoch 95/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9913 - val_loss: 0.2700 - val_accuracy: 0.9357\n",
      "Epoch 96/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 0.2356 - val_accuracy: 0.9415\n",
      "Epoch 97/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 0.9913 - val_loss: 0.2232 - val_accuracy: 0.9298\n",
      "Epoch 98/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9913 - val_loss: 0.3384 - val_accuracy: 0.9240\n",
      "Epoch 99/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9855 - val_loss: 0.3432 - val_accuracy: 0.9240\n",
      "Epoch 100/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9884 - val_loss: 0.2993 - val_accuracy: 0.9357\n",
      "Epoch 101/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9913 - val_loss: 0.2475 - val_accuracy: 0.9415\n",
      "Epoch 102/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.9913 - val_loss: 0.2324 - val_accuracy: 0.9415\n",
      "Epoch 103/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 0.9913 - val_loss: 0.2469 - val_accuracy: 0.9415\n",
      "Epoch 104/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 0.9913 - val_loss: 0.2892 - val_accuracy: 0.9298\n",
      "Epoch 105/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9971 - val_loss: 0.2922 - val_accuracy: 0.9298\n",
      "Epoch 106/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9884 - val_loss: 0.2471 - val_accuracy: 0.9415\n",
      "Epoch 107/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9971 - val_loss: 0.3576 - val_accuracy: 0.9298\n",
      "Epoch 108/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.9913 - val_loss: 0.2743 - val_accuracy: 0.9357\n",
      "Epoch 109/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9884 - val_loss: 0.2358 - val_accuracy: 0.9415\n",
      "Epoch 110/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9798 - val_loss: 0.2986 - val_accuracy: 0.9240\n",
      "Epoch 111/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.2305 - val_accuracy: 0.9415\n",
      "Epoch 112/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 0.3746 - val_accuracy: 0.9240\n",
      "Epoch 113/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.2395 - val_accuracy: 0.9415\n",
      "Epoch 114/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9884 - val_loss: 0.2471 - val_accuracy: 0.9415\n",
      "Epoch 115/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9913 - val_loss: 0.2495 - val_accuracy: 0.9415\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9913 - val_loss: 0.2615 - val_accuracy: 0.9357\n",
      "Epoch 117/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 0.3597 - val_accuracy: 0.9298\n",
      "Epoch 118/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 0.9913 - val_loss: 0.2570 - val_accuracy: 0.9357\n",
      "Epoch 119/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9884 - val_loss: 0.2411 - val_accuracy: 0.9415\n",
      "Epoch 120/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9884 - val_loss: 0.2744 - val_accuracy: 0.9357\n",
      "Epoch 121/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9884 - val_loss: 0.3446 - val_accuracy: 0.9240\n",
      "Epoch 122/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.3141 - val_accuracy: 0.9181\n",
      "Epoch 123/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.2617 - val_accuracy: 0.9357\n",
      "Epoch 124/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 0.3609 - val_accuracy: 0.9240\n",
      "Epoch 125/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.2752 - val_accuracy: 0.9357\n",
      "Epoch 126/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9942 - val_loss: 0.3348 - val_accuracy: 0.9181\n",
      "Epoch 127/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.2275 - val_accuracy: 0.9240\n",
      "Epoch 128/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.4033 - val_accuracy: 0.9240\n",
      "Epoch 129/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.2448 - val_accuracy: 0.9415\n",
      "Epoch 130/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.3346 - val_accuracy: 0.9240\n",
      "Epoch 131/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9913 - val_loss: 0.2813 - val_accuracy: 0.9357\n",
      "Epoch 132/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.2798 - val_accuracy: 0.9357\n",
      "Epoch 133/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.2657 - val_accuracy: 0.9357\n",
      "Epoch 134/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9884 - val_loss: 0.2479 - val_accuracy: 0.9415\n",
      "Epoch 135/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9913 - val_loss: 0.3318 - val_accuracy: 0.9181\n",
      "Epoch 136/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9942 - val_loss: 0.2778 - val_accuracy: 0.9357\n",
      "Epoch 137/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9942 - val_loss: 0.3123 - val_accuracy: 0.9240\n",
      "Epoch 138/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9942 - val_loss: 0.2910 - val_accuracy: 0.9357\n",
      "Epoch 139/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9913 - val_loss: 0.2530 - val_accuracy: 0.9240\n",
      "Epoch 140/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 0.2955 - val_accuracy: 0.9357\n",
      "Epoch 141/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 0.2926 - val_accuracy: 0.9357\n",
      "Epoch 142/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9913 - val_loss: 0.3324 - val_accuracy: 0.9240\n",
      "Epoch 143/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.9942 - val_loss: 0.3072 - val_accuracy: 0.9298\n",
      "Epoch 144/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9942 - val_loss: 0.2638 - val_accuracy: 0.9357\n",
      "Epoch 145/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9913 - val_loss: 0.3664 - val_accuracy: 0.9181\n",
      "Epoch 146/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.9913 - val_loss: 0.3498 - val_accuracy: 0.9181\n",
      "Epoch 147/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9884 - val_loss: 0.2885 - val_accuracy: 0.9357\n",
      "Epoch 148/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9942 - val_loss: 0.4224 - val_accuracy: 0.9181\n",
      "Epoch 149/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 0.2630 - val_accuracy: 0.9357\n",
      "Epoch 150/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.9913 - val_loss: 0.2540 - val_accuracy: 0.9298\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(x, y, validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0988 - accuracy: 0.9710\n",
      "accuracy: 97.10%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x, y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABiF0lEQVR4nO2dd3ib1dn/P0eyvFc8kjiDbJJASAIJYe8Z9miBUmiBtowXuuEtlI6XX3fpgLZACm0oe8+W0IQRIEDIJCF7Lydx7NjxXhrn98d5jp5HsiTLshU71vlcly+tR49uydL5nnuc+wgpJQaDwWBIXVy9bYDBYDAYehcjBAaDwZDiGCEwGAyGFMcIgcFgMKQ4RggMBoMhxTFCYDAYDCmOEQKDIU6EEP8SQvwyzmO3CyHO7u55DIaDgRECg8FgSHGMEBgMBkOKY4TA0K+wQjJ3CSG+EEI0CSH+KYQYJIR4WwjRIIR4VwgxwHH8JUKINUKIWiHEB0KIiY7HjhZCLLee9wKQGfZaFwkhVljP/VQIMTlBm78lhNgshKgRQrwphBhi3S+EEH8WQlQKIeqs9zTJeuwCIcRay7bdQog7E/rADAaMEBj6J1cC5wCHAxcDbwM/BkpQ3/nvAAghDgeeA74HlAJzgH8LIdKFEOnA68BTQBHwknVerOceA8wGbgGKgb8DbwohMrpiqBDiTOA3wFVAGbADeN56+FzgVOt9FAJXA9XWY/8EbpFS5gGTgPe78roGgxMjBIb+yF+llPuklLuBBcAiKeXnUso24DXgaOu4q4G3pJTvSCm9wB+ALOBE4HjAAzwgpfRKKV8Gljhe41vA36WUi6SUfinlE0Cb9byu8FVgtpRyuWXfPcAJQoiRgBfIAyYAQkq5Tkq513qeFzhCCJEvpTwgpVzexdc1GIIYITD0R/Y5rrdEuJ1rXR+CmoEDIKUMALuAodZju2VoV8YdjusjgB9aYaFaIUQtMNx6XlcIt6ERNesfKqV8H/gb8BCwTwjxqBAi3zr0SuACYIcQ4kMhxAldfF2DIYgRAkMqswc1oAMqJo8azHcDe4Gh1n2awxzXdwG/klIWOv6ypZTPddOGHFSoaTeAlPIvUsppwJGoENFd1v1LpJSXAgNRIawXu/i6BkMQIwSGVOZF4EIhxFlCCA/wQ1R451NgIeADviOESBNCXAHMcDz3MeBWIcRxVlI3RwhxoRAir4s2PAvcKISYauUXfo0KZW0XQhxrnd8DNAGtgN/KYXxVCFFghbTqAX83PgdDimOEwJCySCk3ANcBfwX2oxLLF0sp26WU7cAVwA3AAVQ+4VXHc5ei8gR/sx7fbB3bVRveA34KvILyQsYA11gP56ME5wAqfFSNymMAXA9sF0LUA7da78NgSAhhNqYxGAyG1MZ4BAaDwZDiGCEwGAyGFMcIgcFgMKQ4RggMBoMhxUnrbQO6SklJiRw5cmRvm2EwGAyHFMuWLdsvpSyN9NghJwQjR45k6dKlvW2GwWAwHFIIIXZEe8yEhgwGgyHFMUJgMBgMKY4RAoPBYEhxDrkcQSS8Xi/l5eW0trb2tilJJzMzk2HDhuHxeHrbFIPB0E/oF0JQXl5OXl4eI0eOJLRZZP9CSkl1dTXl5eWMGjWqt80xGAz9hH4RGmptbaW4uLhfiwCAEILi4uKU8HwMBsPBo18IAdDvRUCTKu/TYDAcPPqNEHRGq9dPRV0rPn+gt00xGAyGPkXKCEGb109lQyu+QM+33a6treXhhx/u8vMuuOACamtre9weg8Fg6AopIwRYIZVk7L8QTQj8/tibRs2ZM4fCwsIet8dgMBi6Qr+oGooHHVpPxj48d999N1u2bGHq1Kl4PB5yc3MpKytjxYoVrF27lssuu4xdu3bR2trKd7/7XW6++WbAbpfR2NjIzJkzOfnkk/n0008ZOnQob7zxBllZWT1vrMFgMITR74Tgvn+vYe2e+g73+wOSVq+frHQ3ri4mXI8Yks/PLz4y6uO//e1vWb16NStWrOCDDz7gwgsvZPXq1cESz9mzZ1NUVERLSwvHHnssV155JcXFxSHn2LRpE8899xyPPfYYV111Fa+88grXXWd2HzQYDMmn3wlBVJweQZILb2bMmBFS5/+Xv/yF1157DYBdu3axadOmDkIwatQopk6dCsC0adPYvn17co00GAwGi6QKgRDifOBBwA38Q0r52wjHnA48AHiA/VLK07rzmtFm7k1tPrZUNTKqJIe8zOSuys3JyQle/+CDD3j33XdZuHAh2dnZnH766RHXAWRkZASvu91uWlpakmqjwWAwaJImBEIIN/AQcA5QDiwRQrwppVzrOKYQeBg4X0q5UwgxMHn2qMtk5Ajy8vJoaGiI+FhdXR0DBgwgOzub9evX89lnn/W8AQaDwdANkukRzAA2Sym3AgghngcuBdY6jrkWeFVKuRNASlmZLGMEyasaKi4u5qSTTmLSpElkZWUxaNCg4GPnn38+s2bNYvLkyYwfP57jjz++x1/fYDAYukMyhWAosMtxuxw4LuyYwwGPEOIDIA94UEr5ZPiJhBA3AzcDHHbYYQkZE/QIEnp25zz77LMR78/IyODtt9+O+JjOA5SUlLB69erg/XfeeWeP22cwGAzRSOY6gkgp2fBxOA2YBlwInAf8VAhxeIcnSfmolHK6lHJ6aWnEndY6NyaJoSGDwWA4lEmmR1AODHfcHgbsiXDMfillE9AkhPgImAJs7GljgqGhpPkEBoPBcGiSTI9gCTBOCDFKCJEOXAO8GXbMG8ApQog0IUQ2KnS0LhnGGI/AYDAYIpM0j0BK6RNC3AHMRZWPzpZSrhFC3Go9PktKuU4I8V/gCyCAKjFdHf2siaPjVEYHDAaDIZSkriOQUs4B5oTdNyvs9v3A/cm0A+z2zcYjMBgMhlBSpulc0CMwSmAwGAwhpI4QJLF8NNE21AAPPPAAzc3NPWyRwWAwxE8KCYGqG0qGQ2CEwGAwHMqkTtM5ACGSUj7qbEN9zjnnMHDgQF588UXa2tq4/PLLue+++2hqauKqq66ivLwcv9/PT3/6U/bt28eePXs444wzKCkpYf78+T1um8FgMHRG/xOCt++GilURHxrd7iPNJSDN3bVzDj4KZnbolxfE2YZ63rx5vPzyyyxevBgpJZdccgkfffQRVVVVDBkyhLfeegtQPYgKCgr405/+xPz58ykpKemaTQaDwdBDpExo6GAxb9485s2bx9FHH80xxxzD+vXr2bRpE0cddRTvvvsuP/rRj1iwYAEFBQW9barBYDAA/dEjiDFz37G3nvzMNIYNyE7ay0spueeee7jllls6PLZs2TLmzJnDPffcw7nnnsvPfvazpNlhMBgM8ZJSHkGyksXONtTnnXces2fPprGxEYDdu3dTWVnJnj17yM7O5rrrruPOO+9k+fLlHZ5rMBgMvUH/8whiIERyykedbahnzpzJtddeywknnABAbm4uTz/9NJs3b+auu+7C5XLh8Xh45JFHALj55puZOXMmZWVlJllsMBh6BXGoLbCaPn26XLp0ach969atY+LEiZ0+d0NFA5keFyOKczo9ti8T7/s1GAwGjRBimZRyeqTHUis0JEyLCYPBYAgntYQA03TOYDAYwuk3QhBPiEsIccj3GjrU7TcYDH2PfiEEmZmZVFdXdzpIJitZfLCQUlJdXU1mZmZvm2IwGPoR/aJqaNiwYZSXl1NVVRXzuP0NbUigfX/GwTEsCWRmZjJs2LDeNsNgMPQj+oUQeDweRo0a1elxNzy+mJqmdt68Y2ryjTIYDIZDhH4RGoqXNJcLr/9QDg4ZDAZDz5NSQpCeJvD6A71thsFgMPQpUkoI0lwufEYIDAaDIYSUEgKP24SGDAaDIZzUEYI9n/Plij+S76vubUsMBoOhT5E6QnBgB8fXvEFeoK63LTEYDIY+ReoIgTsdAOH39rIhBoPB0LdIqhAIIc4XQmwQQmwWQtwd4fHThRB1QogV1l/ydmqxhICAEQKDwWBwkrQFZUIIN/AQcA5QDiwRQrwppVwbdugCKeVFybIjiFu9VWGEwGAwGEJIpkcwA9gspdwqpWwHngcuTeLrxcbyCNzSSyBgKocMBoNBk0whGArsctwut+4L5wQhxEohxNtCiCOTZo0lBB78eANmLYHBYDBokikEIsJ94VPx5cAIKeUU4K/A6xFPJMTNQoilQoilnTWWi4pLhYY8+PCZtQQGg8EQJJlCUA4Md9weBuxxHiClrJdSNlrX5wAeIURJ+ImklI9KKadLKaeXlpYmZk3QI/CZNhMGg8HgIJlCsAQYJ4QYJYRIB64B3nQeIIQYLIQQ1vUZlj3JWfFlCUEafrO62GAwGBwkrWpISukTQtwBzAXcwGwp5RohxK3W47OALwG3CSF8QAtwjUzWFlxW1VC6MB6BwWAwOEnqfgRWuGdO2H2zHNf/BvwtmTYEcYSGTI7AYDAYbFJuZXEaftqNR5A4leth83u9bYXBYOhBUkcIrKqhdHz4TPlo4nzyIPzne71thcFg6EFSRwhMaKhn8LWCt6W3rTAYDD1IygmBCQ11E387+Np62wqDwdCDpI4QuNwAeITxCLpFwGeEwGDoZ6SOEAhBwJVOullQ1j387eBvgyRV+RoMhoNP6ggBIF0ea0GZEYKE0fs5+Nt71w6DwdBjpJYQuNOsFhNmNpswWgBMeMhg6DeklBBghYZ8xiNIHOMRGAz9jpQSAun2mKqh7qKFwNfau3YYDIYeI6WEAJfHVA11FxMaMhj6HaklBO5004a6uwRMaMhg6G+klhCkeawdyoxHkDAmNGQw9DtSSgiEy2O1mDAeQcIEQ0PGIzAY+gupJQRpJjTUbYJVQyZHYDD0F1JLCNzpeITZoaxbBENDRggMhv5CigmBx3gE3cVUDRkM/Y7UEoI0vaDMeAQJo4XAhIYMhn5DSgkBwdCQ8QgSIuAHLBE1HoHBkFz83oPW3DG1hMCVRjomR5AwzrUDRggMhuThbYU/HA5rXj0oL5daQuBOxyNMjiBhnEJgFpQZDMmjtRZaaqBm60F5udQTAvxmz+JE8fvs62ZBmcGQPNoa1eVB2hY2xYRAtaFu95nQUEKEhIaMR2AwJI12IwTJw+o1ZDyCBAkRAuMRGAxJo71JXXqbD8rLJVUIhBDnCyE2CCE2CyHujnHcsUIIvxDiS8m0B3e62aGsO+jFZGDKRw2GZBIUgkPcIxBCuIGHgJnAEcBXhBBHRDnud8DcZNkSxJVGGl5TNZQoAYcQmNCQ4VDmpRtg+ZO9bUV0dGhIC0KSSaZHMAPYLKXcKqVsB54HLo1w3LeBV4DKJNqicFsLynz+pL9Uv8SEhgz9hc3vw85FvW1FdPqLRwAMBXY5bpdb9wURQgwFLgdmxTqREOJmIcRSIcTSqqqqxC1ypwPg9xshSIiQ0JDxCAyHML6WgxZ/T4h+JAQiwn3hMZkHgB9JKWOOzFLKR6WU06WU00tLSxO3yJ2mzmfi24nhFAKzoCw+fG0HbXWoIU4CfjWR6dNCoKuGDv1kcTkw3HF7GLAn7JjpwPNCiO3Al4CHhRCXJc0iyyOQJr6dGGZlcdfwtcEfJ8Cql3rbEoMTHdbs00JwcD2CtCSeewkwTggxCtgNXANc6zxASjlKXxdC/Av4j5Ty9aRZZAkBAV/s4wyRMVVDXaO5Wq0Ord7S25YYnOjB9SANsglxkMtHkyYEUkqfEOIOVDWQG5gtpVwjhLjVejxmXiApuKzQkPEIEkNXDaVlGY8gHlrr1KV28w19g0NCCA5uaCiZHgFSyjnAnLD7IgqAlPKGZNoCBD0CETBCkBA6NJSRZ4QgHlpq1WVbQ6+aYQhDh4YOUmlmQpiVxUlE5wicIQ5D/OjPLSPXhIbiwXgEfZNDwiNwhIYOQrFBigmBcoCEEYLE0B5Beo5ZUBYPQSHowzPP3mDHp7Do7733+sFk8SEgBHBQ1uykmBDoZLERgoQIegT5/WtBWWs9VKxKwnlr1WVbNzyC+j1wYHtPWNN3WPEMzP91772+jrv36aohx3fmIAhWSgqB8QgSJOgR5PavBWULH4J/ngs93Yww6BF0I0cw5y549Zaesaev0N7cu4Ow15rEBLyhlXC9RaTvndMjOAgeZWoJgVU1JIxHkBjOHEF/ShbX7lADU1t9z563J0JD9XugqRur6fsi7U1qItFb4UWfY4bd215B/V74zTDY+kHo/e1NkJ6nrhuPoIcxVUPdQwtoej8Tgoa96lKHcnqKYNVQN0JDzdX9L8cQDM0k8X1Vb4k+2/c6wpq9nSc4sF19DosfC72/vQlyStT1gyBWKSkELrOgLDGc5aP9qWqooUJd6oG7p9DC0p2qoZYDh07VUcuB+EpltbB1JnAVq+CJi7s+WLfUwsPHwxcvRH7cObD2tkegvcaN/4VGy/MLBCwhsNrpGI+gh7GqhtzSRyBg+r90GT3DSs9RotCVsra6cnjpRhUf7mtoIehpj8AZGkok/+BrV+GqRJ9/sHnhenjrzs6Pi1cIdiyEbR9B7c6u2dG0X30/a3dFftxZ6NDb30f9HQn4bOHytQDSIQTGI+hZLI/Agw/vofDD6mv4veDyQFqGut2V8NC2j2DNq7B/Y3JsSxRviy0AyfIIkIn9mFsOdO/5B5vanXBgW+fH6ffSmaejPz89WMZL8P9ZE+X1WyJf7w30eysaDZ8/rSZXWiBNaChJuDwAePCbzWkSwd+uxNRtCUFXwkPN1eqyt3944WhvAJLnEUBi4R39mcGhkSdoa4DmKIOvk3g9Av35JSwEByI/7vQIeltg26z3dtxtULUO9iy3w2u5A9WlCQ31MG4tBD58ZrvKruP3qvBa0CPoQtJdDxC+PiwE0QaORGmtg8xCdT2Rgdw5o+3reQIpVRjLKV7RCHoEnXwm2kPrshBYx0cTpb7mEXiyYeJF6vaezx0egRYC4xH0LDo0JHy0GyHoOtojCApBFxaV9VmPYK99vSdDQ4GAWqhWYHViT6TfUIhHkGQhaK6BBX9K/DPwtqg4d2ut6vcfjYA//l4/wdBQFJvq96g23+GLAfV7iCs01MueVmsdZBZA7iAQbjUx6RAaMh5Bz2J5BGn48ZnQUNcJeMNCQ13wCPSPsq8JQeM+denO6NnQUFs9IKHA2pQvodCQ0yNI4oBVvhT+fiq8dx+sfjmxc2ihk4HYM/iQhVKd5Qh0aCjK+o59a5WQb3on8vOieQS+VoL7ZvX297G1Tq3Ud7mVGNTvdQiBSRYnB0sI0vHhNR5B1/F71WeYZrXq6EqyuLmPCkHDXiUChYf1rEegB6N8LQQJDOROj6A7axFiUb8XHp8JCEjLhOqtiZ3HuRgvVp7AOajF7RFEEZYma5vzPcvDnmcdHy3U521Rs3B9vTfRHgFA3mD1fdQCmTUAhKvveARCiO8KIfKF4p9CiOVCiHOTbVyP46waMh5B1/G3W1VDmep2l0JDOkeQhB5F2z+Gqg2JPbehAvIGQVZhz3oE+lzaI0gkNOQcyJIVGjqwXf1fL34AisZATYKb6Dhn7bHyBF1pndDSSbK40RKC3Z+H2VKrLtvq1eRFSnjx67D5XXW/twWyi63rljAt+COseDa2Pd3FH2H9Umu9QwjKLCGwPpeMXJU/OAglrvF6BDdJKeuBc4FS4Ebgt0mzKlm47NCQ8QgSwK9DQ5ZH0JXQUDBHkIQv9Ru3J97ErGGv+gFmFibJIximLhOtGhJu6/lJCg1pgcoshOLRie+m5vQIosXmIcHQUDSPwFqAVV8ODfs6Pg+UmLbWwtrX7TYOvhY12wZ7kF32RHxCsOI5+Pd3Oz8unF2L4TdDO36+To8gP0wI0nPBk9WnQkN6I/oLgMellCuJvDl930aHhoTP5AgSIRga0h5BnKEhKR05giR4BM0HEu/H07BPueRZA3rYI7AGo4LuhIZqupdjiAc9gGfkKY/gwPbIM9d4zwOxPYJ4Q0MBv11aGdUjcAz+zvCQ8/jmGhX+Attr8baqATbNMci21Ma3cG3TXCUGXd0jYOdC5Q1rr8RpqzM01HIAmver2+k5yiPoK6EhYJkQYh5KCOYKIfKAQ29KLQQBlwcPPtr9MSobDJHxt1tC0MUFZW319j7RPT27CQTU+Zv2J/b8hgrIHaxCQz1ZPqq9i/wh6jKRGH9zNRQcpq4nTQgsjyAjD4rHqIKAuigrcmPRGmeOIN7QkFNYojUDbKyEQZNUHH23QwhaaoPePy010LAn9Dy+FjXAerLUIOv3KdGp3xO74gnU/8Tf1vXvW5W1kHL7Avs+KS0hyFe386zvSvUW5QmmZVpC0Hc8gm8AdwPHSimbAQ8qPHTIIV1ppOGnzXvo6VivE/CFhYbiFALnwNATOYLN79mzt7Y6QMb2CGp32T9EJ+1N6vl5g1VopLW+51o56FlpdrGaeSbSirqlRuUv3OnJSxaHeASj1fVE8gTOHEjcHkGM9+QM08UKDQ0YCaUTYfey0OMHjLBsqVEDPIR5BI5BNtjmwRvqZUSi2ZosdFUs9Yr67Z/Y3zFvi3pNp0cAUL1ZhYWEsMUqycQrBCcAG6SUtUKI64CfAF1c5dE3kJZH0OYzQtBlgh5BF0NDTiHoidnNSzeqPQQgtEIk2mxu3r3w6rc63q8Xk+WVKY8AaYcjuktrnZqppucpFz/R0FB2ceLPj4e2BsvOHBUaAqiJo01Eh/NYg2x2SXw5gqyi2O9J/19zSmMni3NKYejRKjSkwzWtdTBglLre4ggNaRu9LUqcdfzd6QnWlUe3SZ8vnuOcSAn7N6jwY0uNWkHstMeZLAZLCHLU9T4WGnoEaBZCTAH+F9gBPJk0q5KJO510fLT5TGioywSrhrpYPuocGLqbIwgE1GCtPYDgzFFGD0k010SepQaFYLC9ArinEsattVZ9uEtVf3R1Ru+3FmdlFSkxSaYQZOSp2WfeYPDkJJYwbq1Xz80dGF9oKHdQJ0JQqy4LR0QWAr9P/U9zB8LQaWowP7DdCrfU2t5NsyM0pM/ja1EeQbo1yIYIQSczff096ooQNFaq1576VXV7+8eh9jiTxaA8paAQZB2URW/xCoFPSimBS4EHpZQPAnnJMyuJWKGhVhMa6jr+8AVl8XoE1o/HndF9j0C3qNCDjXOQiBYeam+MHGduDPcI6LmEsTMJmJ7X9Ri/tiPoEXRjl7NYtDUowQIlBkWjEwwN1atYd3ZxfOsIcktjC4EW5MLDVDgxfNLRXE2wQ+eQo9V9e1eq8wd8alB1p4d6BCGhoWw7NOQUgmgdS0FVGOnQphaMyvWw5B/RnwN2WGjsWUrYtn1k2RMmBJmFtrcdIgR9xyNoEELcA1wPvCWEcKPyBIce7nQ8wngECRGsGupiryE9MOQP6X6OQA8e+sfrHLiboyTw2hrVgBde6RH0CAYlwSOos8UlI7fr6wi0eGYXqecnzSOoVx6BJtESUn2erAHxrSPIGRhbHPUgWWgly8NXF+vFZLkD7dl/7Q7H4FqovKmWA5GTxWmZapBt70JoyOnZaiH47CF464exBWS/tcalZDyMPAV2WHkCbWuGJQRC2OGh9Fx12ceSxVcDbaj1BBXAUOD+zp4khDhfCLFBCLFZCHF3hMcvFUJ8IYRYIYRYKoQ4uUvWJ4BI06Eh4xF0mUR7DTVXqzh0Xln3Zzd68GiJ5BFEEYL2JtX6IHwwbdirBoTMwp73CFpqHR5BAjF+LZ7ZRer50UJLB3bAun8nbGYwNKQpGqMG1K6WkGrPIru48xyBO0N5D3GFhrQQhIWH9GKynIHqc84oUIOxFvLMAvXZOZPF3ma7J5Iny46/ayHIGxI7NBQUOGELRsVqdblpbvTnVW1UA3v+EBh5snq9qnUdPQJwCIHlEaT3oRyBNfg/AxQIIS4CWqWUMXMEltfwEDATOAL4ihDiiLDD3gOmSCmnAjcBnfhYPYDbY6qGEkV7BF3tNdRSo2aKPfGl1oOHrt6ISwisQTR8Vt60X4UWhEiOR6DPmZ7b9dCQHnSyiqznRxk0Fz4EL92QeLVTuBAUj1EDZe2Orp2nVYeGrME3Wp29t1kNcp2JY2udKqHULTrChUCHAXWr5sLhahDXx2UVqu9cQ4X6LLOtBm5aQJylmVoIBk+K7RFocS4eq44L+KHSSvxujCEE+zdCyTj1PSubrO6rjCIE+WFC0JeSxUKIq4DFwJeBq4BFQogvdfK0GcBmKeVWKWU78DwqxxBEStlo5R4AcoCkr/JyudPx4KPVa0JDXSaghSBN/UjjrhqqVgNaT8Q79UrQ9gYVmmqpVd4GInJoSMroQtBcbbca0B5BT60lcOYIEkkW61l1dnFsITmwTQ3cieYQOngEuoS0iz2HdGgouxikP2wvhmY7tNOuhSDXiudH+R1qjyqapxb0CKzGbAXDlEfgHFyzBkDVenW7dELo8zxZ9vex5YA6vnBEbI9A/0/KJish2rdGhZlyB8HWD6ML2/6NKiwEdjVTzdbYHkGGDg1lWR5tcofGeEND96LWEHxdSvk11CD/006eMxRwfqrl1n0hCCEuF0KsB95CeQUdEELcbIWOllZVJbiCVJOWTrowoaGE0KEhUOGhuENDNXY9fXf3I3AOiK219oCbXRTZI/C2qLAQRPEIrJmiJ1u9tx5LFtc6QkMJxPidOYL0nBhCsF1dJurJRAoNQddLSHVoKKtI3XbmCd6+C569Wl1vb1SftZ7xRot/6xyL/gzDk/2N+9T3SdteoD2CWnU7s1B9dvpzK7UGYl0gEAwNWR5B1gDlVbTWRe92qj2CsinqUnsBJ35bFU5s/dA+Vkq1B3FbA9TvhtLD1f3p2artSPVm9VrudFXBpNFrCdIdQoDsWoPHBIhXCFxSykrH7eo4nhupBUUHWZNSvialnABcBvwi0omklI9KKadLKaeXlpbGaXIUo1we0oXfJIsTQW9VCeoLHG9oqLlG/Sh7xCNwDKjNNfaAm10SuWrIOYCGDybN+22PQIeHeiI05GtXA4yezabnqhl7V2Z1zTV2+CJasjgQsBfWhXsy+9bCm9/uPKHvrBoCNcN2Z0BdHO0W/F47JKWbp2UXdbSnaoNdOeNtVoOhFoJoAqn/r9q2SKGhXCusB2oQb6u3Pw+dLNYEPQJrwZhOFjuFoMDqCxUtPKSFYPBR6nLj2+BKg2k3qsqwjf+1j13zKvxhLDx+gbpdcrj9mE7IO71GTXiOwJOtLpOcMI5XCP4rhJgrhLhBCHEDavY+p5PnlAPDHbeHAXuiHSyl/AgYI4QoidOmxHB7yBB+4xEkgs4RgPohdWUdQVAIeqhqSJ9X/5hySiJXqzi9gA4egSN2DIl3IG1vgldvhrrd6razcgXUQC4DXRPB5ho1kAmhhMTX2jGB27jP9srC7X7vPlj+JOz6LPprBPxKKJ0egculBtVYfXfqdsN/74HfjoD5v1R2eZvs0BCE/i90nN7vtUJDufaMN6oQWDkWPVBGShbrHbzA3gBon5W81fkKjfYIdHM67REEfKoCKWuA3c4jWniopUYJkw7v7F6mQj4ZuTD2TOUhaLHf87maNDVVqdClFg9QOYaaeIUgS10mOU8Qb7L4LuBRYDIwBXhUSvmjTp62BBgnhBglhEgHrgHedB4ghBgrhJJ0IcQxQDrK20gebhUaMjmCLiJlWGgoPT4hkDIsR9DNmY1zcU3LAXvAyCmJHBpyDjROj8Dbos6VU2zfl6hHsPMz+OIF2GaFBnSuQg9EnQ16kWipsQfV4PPDwkM6LAShM/DK9fbsdMv70V9Dn88pBKAG1WjlkFLCvy6AxY+qAa58qZ2fyMi3u3rq2XMgYJXpSvX/8TaFhoaihbx0jiA9R+WjInoEDiHQ1UUVq9XCNrfH9gg82UrcINQjSLdm2/V71LFBjyDKe2+uVv/T/CEEAx6DJ6nLkaeosJOuUNq/WSWIv7sS7liqWmFoisbYC+DChSCYLHaUj0LfEAIAKeUrUsofSCm/L6V8LY7jfcAdwFxgHfCilHKNEOJWIcSt1mFXAquFECtQFUZXO5LHycHtwWM8gq4T8AMy1COIZ0FZe5MSEJ0jCHgT627pPJ+mucYeMOIKDUXoh9MTHoFOSGoh0pf63MGB3PH6fl/sSp+6cnugizZohghBrX194V/VZz3wyNhC4Gw450RX4ESiuVq97tn/BxMuULkEHVPXC8r0caAELeBV15sq1f8vrtCQlSMQQv1/I3oEjjCx9ghqttohOS3EeWV2rb4WAt10DtT3JmuASvq6PLFDQ1lFKj+WO0jdN8gSgoET1aVuH1G9WVVgpWWoSyf69r7VHYVgwCiYeT8ccZltJ/RuaEgI0SCEqI/w1yCEiJJRsZFSzpFSHi6lHCOl/JV13ywp5Szr+u+klEdKKadKKU+QUn7cM28rBm4P6aZ8tOvofIAWAndGfAvKnElP/cPrTsI4Umgoq1B5BJH6DYV4BI6BWA/WOQ4hSNQj0CWEWoiaw86tK0CclUOPngYfRVmK4/epuLoeXKINmk4h0ALWUAFfvAhHfxWOvFytto1WVhtVCA5T7yXShijVm9VlyXhVYVS3yz5/Rp4a2ITbrrDRi/ZADd7tzWrGHstL0m0igituC0ITuAG/+oydHoHObSDt52mPIH+I3eEzKASZ9iALSghcLtX2e9tHsGV+R49XhzjB9h60R1CqhWCD+v8d2AbF4zq+N1ChIVC/KWd+BpTwHXezyn+AIzTUi0IgpcyTUuZH+MuTUubHem6fxfQaSgw9qwsJDcUR73eWQQa/1N3IE7Q3qYHE5bE3HckssGaHEfoNheQInK2S9azdERrKKuyeEGjR6+ARhA3kfq8qPdy5MPL5arYqb2vQkeq2HqjDPYLaHarO3p1uh4bWvK4GmONugzFnqvv0hizhRBOCYKw8wsx4/yZ1WTzGKjWVUPGFdZ58NZBlF9mfRYgQ7FOhIb2OINJ7Aisf0m7nWMI9guYalXNx5ghcLntwDgqBFabKK1MTGE+2Yx1Blv19dB47/kIV33/qMnj2qlC7nOXG+rUGWbH/nGL1Haxcp/4vAZ894IdTOMIqeaajRxBOX/AI+iUuj+k1lAj+cCHIjK9qyLkwqidmN+3WQKIXC/lardCQ9QMNDw9FCw01RQgNZRaqhnad9aR3ImXH0JDTCwJVUeK0pXEfIKO3cqhcoy4HWusv9aAZvhbhwHYVSnB6MvXlapArHgNDpqrHtsyP/Dp6lh0+K9Xx9EiVQ9WblQgXjrDXHOxdoS71rDuryBbkhr32cxv3WcniTkJDztXB+rwhCwd1e4mwCkJttxYQ/fnruHtGfphHkGM/VwvB+b+GH+2AU+9SArprsX1M8wHbyxh5Mhx2YqgNpRPUd0F7TdGEIC1dfX7O9xiNvpQs7le4dRtq4xF0CT3ou9LUpTvOZLFeAZxdFHuvYylhzWudewtaCLKL7Fr3zEI7Xhy+qEwPNNnFYTkCHb5xeAR6wHAOXp1Rt8se4LUINe1XNukwWjA0ZL2+niXX7Yr8A69cp2aMutIlWhjlwHaVhMwaYHsEjZUqZCIEuNww+nSVJ2io6Fi+6tyLwIlOvEZKGFdvhqJRalFhUAhWWuexhCCn1B5w9XtNy1LVRgFv56EhHebSsf5wj0B7KrrCRqPzBHpwzS6GCRfBOGt79cx8e4OkaB6BPu6k76n/4ad/Vff52lWOR4vLjG/BTW+Hvn7pBKtUVntNUYQA7DxB3B6BEYKexZ1OGt6+lSzevQw++F1vWxGbDh5BnAvKgj/qAbHd3P2bVKuEtW/EPl97kxpEsopUHBbsqiHoGA/Xs+i8so45AleaPXuExFbVVlreQOEIW1ya94fmHsJnv0GhieIV7FujbNEDVaSqIW+LOs+AEaFJ7sZ9diITYNw5qunaH8fD/WPsTpwQPTSUV6Y+m0glpNVb7Nh31gA1kO2zPBgtBCXj1IAopbIxy6q00f+vEI8gQmioQ1fOMCHQoSjtMWm0gOnnudxwzTNq9u60D+yVxRqnEIAS7+k3qT5ONVsdIc4iolI6Xonr9gX2grZoFMUrBH0gR9AvcXtw08eqhta8Bh/8umshiYNNJCGIJzSkB6iMfHsFZaRZvw6n1HfS5729UQ0k2UX2rFNXDUFHIWhvVDZnF4Vtp2jFe/WCJEhMCHSVyMhT7HBT0/7QkFP4QO6Mm1dv6njOyrWhg1xGBCHQs/VoHoFm8jVw3atw2o/Ue961yH4sKARhoSGXWw3c4ZVDAb/6bPRsVret1t8DHRoqnaD+742V6r3mDVbipD249Bz1P3GldRIasgbnzMLQ/M7eL6yQWJjd2iPQnkQ4meFCEJYsDmfGzcrGhQ/boa6sGIO7Tu5vma+8Aed3KxztLXQmBEHBNELQs7g9pMk+to5A/5Oj7c3aFwhWDenQUEZ8oaHWOmsVZ2Zsj0DP+PSCn2jopmXOH3tWoTX7itBvqL1RDcQZ+R3LR52DNdiJ186EYN1/4K/T1D65levUDLp4jEqEtjerczs9Aj3j1q9fv0dV1oCqNw+xt0kNmDpRDJHj6bpiaMBIK0dgfX7hHoE7TfXBP/n7KtykF1w57dFC5aRwRMfQUN0ulcR2hjy0eLrS7NCfDmlVrVe19XmDlThpYfHkWAvlojSei+QRtDfaZccVq+zmbSE2h4WGwgnuu+BWYbv0ToQgvwwmXaHWiOj1ATE9AksIwj+jSARDQ4Wxj9MeQZLHhhQUgnTcso+FhvTAGG1Lvr5AxKqhOIVAf9lj5QiCQtBJfD6YLHb8IDML1Cw2Ur+hNi0EeR1DQ+E/apdbDayxhGD1q/Di11Ss/M3vqAVMpRPsgb95v3VuR+7B7VFxcx1qaahQ4pE/tKNHULUekKEegSdCstgpBFkD1Azc77V27XIIQfAcWSqkUxEmBOl5quImnIIIq4uDpaOOskgtBLpiCOx2DlUb7PeaO8iOz+sBOD1KM77KtepS52/0AN5Wr74nB7aFrtTVFI9T30+diA1HewR6cA3xCAojP2fy1ep1v3he3Xb+X8PJKbYnFyWdCMGo02Dm72H0abGPS8tUlUmLH4teBtwDpJ4QuDy4kHi93t62xEbPiqI1u+oLhIeG4t0ww9mXP1biy1kHHws9w3cO4lpocgaqQcSZFG1vVKGVjLyO5aM5YR4BWDt0hTVcq90Fz38V/nYsvHwTDJ8Blz0C+1apv4ET7WR1Y1VHjwDUDFHnAxr2qtlm8Vg7sajZZw2CTo/A5VJi0B4mBGlZ6nWzCtV707NWZ2jIyeBJYR5Bfcf8gKZwuLLTuVZEey+RPAJn2CVvsPqfV651hIYcNunvQaRmeo1VatA74jJ7lq6/Py0HbCEbPKWjzXmD4PtrYMKFkd9TRrgQ6BxMnp3YD2fUaep7tcZaQxsrNAR2eKgzj8CdBsfdYu/tEQ0h4PJZ6vfx5neS1oU09YTA+ocH4t1d62CgB8a+7BGELyjLKVVfzs4+R2c/lWCOIJIQ6NBGZ0JgtSgI9wgApn1d1eZ//pTj+DCPQP+QwuP4mqLRyiNw/uBWPgfr31KNw06/G657BaZ8BcZbDcVKJ9jnqtmi2jCHn7t4rD2jbtirBseSceo+52tVrlUDvLMlAXQcNKs32XFoPWBqUYnkEYCaRdftsvMJ4Z1HnRQeBkjVOTP4mpvVYOpc0Rv0CBznEUJ9Jjs+UZ+F9giC7yXX8Z7CQkML/qA8xjN/Yt+nw0Cb5qmwkPO+cHTFVCT09yQtK/QyUlhI406DSVfa3kys0BDYYbHOhKArDJ4EZ/0cNryl+kclgRQUAjWjlb52kt3NIm4OhdBQsHzUEgL9w27sJKYfIgSxPAIdGopQ5uhE97PXP153hi0wM26BUaeqhmh6Vq9DSRn5alDytijvprU2ukfgbQ71TLa8r2ryr3lGCUG6FeO+4A+qPHHs2XYYQ68piOQRNFmbmDfstfIK49SsXC9yAitRPEGFqZyEdyDVm52A7RHp144mBHrxk67yiSUEOvHqDA9Vb+6YBA0KQVhcvnS83XE0d1CoR+AMDTnf0761sOSfcPR1oeGnQUeqDeqXPaEqhnJKo7/HWAQ9Auv74nKp0Eu0sJBmsrWwzNmWIhpjzlKfSU8KAcDx/wNHXBr9/9VNUlAI1ECW1pe2q9Q/hj6dLLZmRDo0pGu4OwvlOIUgmCOIERryt0ffHCbgV891hoacP2KXCy59WCVF37tP3dfmCA2BGvz0+SPFe4scG4do+3cttlfpOikYqsShYKg9S9blpOHn1gNDxWp1zrwyO46sPQVQcXUdY3finD17W9UWlbq1cdAjsPbGjRUa0jZAJx5BDCFwklOq/h/hFTzO95BXFjs0tPcLeOJieOQE9R05LUI/y2O+riq01r4JgyfHrsiJRvj3UNsSyyMAGHK0et+dhYVA9V/6zuedC0ZXcbngqidV8joJpKwQePpSCemh5BHo0FCe9gjiEAI9WMdaJel879HERQ+E6Y7QUHiFSOFw5RXoAdlZNQRKbIMtICIJQVgJ6bYFypOIJARO0nOVdxLLIwDYbrXT0h4B2Anj1nrlLTh71wfP70h212wBpD1r1p9vVSdCkDtIhaz2WeGVmB7BYerY9W+p25XrVFipLCw2LwQc9SW1cM2JDpGAXT4afC859mXDXnjmS8r2M34Cty9SwhrOpCvtfR2ihYU6IzxZDJYQFMZ+nhAw83fKG+ynpPW2AQcda0ardinzA1GSRAeT9kNQCHKtnZRieQRShnoELrf6/KMJgStNxWIb9sKgI+xzzP+1aqCmZ256ZTFELr/LtxqHQWiOAJQQaEGJFBoqOEzZoYVgy/vq+cNmRH+foAaLnBJ70VR4jqBoFCDUYiNQg2PBcDU71bF9fRlRCHLstRY65KKPC4aGNqjPKFoCUgjlFYR4BFFahrnTYNoNsOCPyvv47BFl69RrOx578YMd73N6BLmDQmfwTiFoqlIi98137ERrJDJyleAs+1fkiqF4CE8WA5x5b/QqIydjz07sNQ8RUs8jcDlCQ32l35DusX8wq4aeulxVZ8RLICw0lFOiQjCxhKC9Uc2mnbP2aLuUtdTaqy3DO1Z+9HtY9ZLtOaXndqwocVIw1Co1rI8cGgpvCufEnaYSpU4hGHmKKpftjJwSe1vMcJFJy1Dn1b1r8sqUu19yuF3Jowd452xak1lgt7AIb2GgP4vW2s5j54Mmqdm93xfbIwCYfqP6H3/0e1VLP+WazpOlmvyhVgivRH12bo/tgYUkaQV86Z+xRUBz/O2qv8/IU+OzIRztEaQ5hGDqtTDypMTO149IPSEICQ31kUVlB7tqKBBQ+6tumhf/c8I9ApdbDTqxQkORNueOtm9xa529r6vznLU71GX9HrtqJj1HDayenMhCkG+FFg5sV+sf0nNChUDPrCN5BGBXDtVsVTP8zsJCmmC30bzIs/KScfYeDrqv0dBpqttlIKBi/K60jhVDAIcdr0Iz1VuUYBQcZiddnaGNaGEhzeDJyobKNbHLR0F12JxwAXz+tKrkOe622Od2IoQSNGc/oNxBKhSj1y2c+B34xjw4/Lz4zll6uOrvE95sLl7Ck8WGICkoBFZoCF/f6EAa8NsLrNq6KQR+L8y9N7SfTCRaa9VMXceU4zp3WNUQqB92rJXAkYQgmkegE6iZBaEegV44Vb/bDunoZOPEiyMvyNFCoGfY6XmRPYJoyb+i0eqz+ddFakY89qzo79GJFpacCLkHsGfwnmx7UBp6jHrvNVvVTL9oTOSadm3DlvdDK4bAWiVrlWR25hGMOUOJ8Ye/B2TnVSgzbraed6aqZuoK5/4Kzv2FfTunNHQRV06JWpNxsAgvHzUESb0cgVUxkElb30gWOxdlddcjqFwLC/+mBpzpN0Y/Ts+Ia3fa5ZWV69WgEClRBx0XlIGKc+t9eiMRvncvRBaCQEDNTjMLVO7Bubr4gOURNOx1JIutQe+Kv0d+Xf0edOI23eE5tDXYe9S6o3z99ay5aDRc9nDHHaaioSuHoq0+1UKQN9iOmQ+dpi53L7MG+Aj5AVC2FI1WXtz+TXDMiaGPZxYqj6kzIcgdCDO+aXfV7EwIRp4Cp/8YJl4U+7hIjDgh9HbR6I77RRxM9Hvt6YqefkDqCYHlOg8UtbT1hX5D7T0oBMHN02tjHxdcqi7VoDJkKjzzZXV59VORnxMUAsdsNW+wGsCiEa9H0N6oYuuZheqcTi8j6BGEhYZikVcGCFsIMnJt8WirV3H6WAnHqdeqGXA0UYyGFoBIuQewBcUZLimdoEJcuxYpr2DixdHPP/ZsVWcv/aEeAShhqy/vPDQEqsXyktn2hvOxEAJO72x78jg55/8lvYtmTNweNdHIG9x7NvRRUi80ZIUNBouaPuIR6AU1ovvJYr0KNFodvsbZmK1qg2qhULezY7sDJ8EcgcMjyB2sREWLRDhRcwRhvYa0cGUWqEGyIUKOwNtst1BwNguLhNujZsZVjtBQWrpVobNZJWdjxf1d7q6LADhCQ9GEQHsEDiFwuVVJ5trXVUI+mkcASgikNXkJP07nCeJZaJVTotobQPSqoWSQmd/7g/DNH8CJ3+5dG/ogqecRZBcRcGcwyHegbySL9ew4p7T7HoEeKDsVgmr7etV6exXrgW0qTBOpCVlEj2AQIFVlT6SBM9hOuNC+z5PVsUOoUzDyrAS0lGo2emC7mjF7mxwx/wjdMsMpGGpvmKI9iIw82GBtJhJvArgrdBYayh+mZu7hoaahx8DOT9X1WEIw8mQlxP72GEIQh0cAcPL3ANkxfNPfyS/r/JgUJPU8AiHw5wymrK94BDo0lF+mBsTutL0ICkFt7ON0aKhwhPIIdn6mbvta1SYmkdDdR12OuYOe2UarHAoO8M4+8Jkd9yMIEYIye3Wxr13tRjX8WPW49lg6Cw2B8vx0yavu55+RpxLy2SV2u4WeJLsTj8Dlgls/VqEZJzpPAB1DPk7Sc2DEiaqdQ/iAr8U23tYLmQVw9v8lrWWB4dAi9YQACOSVMVjU9I09CXRoKK/M6oXTjRhq3KGhajXLLpuiPIJdi+xWx9FaMPvb1WzUuTBIDzrRKoda66wVtw4vIlLXUi0EWYV26KBhr9W/XsIIq857/yZVxZMWR/mf3lwcQj0CUJUzkbye7lIwTPW6j7VAqWBYx9DW0GPUZf7Qzgfmc3+pulGGt1jQawkS6cFjSHlSUgjIK2MQB/qWR6AHwK6EhyrXw4NT7DLQoBDUxn5e035V4lg6QYWD9q1WDa0ghhB4Q0tHnTZH20PAuapYk5apPI/mGnj9dnUZ7hHoc+pE8fAZSgCaKu1NTToj3xGq0pvH63h4MsJCoLy62xfDxEu69rzCESqcFMsb0Aw+StX2hzPsWBg6Pb5+OAZDGEkVAiHE+UKIDUKIzUKIDo06hBBfFUJ8Yf19KoSI0GQ8CXYVDFWhofa+4BFoIbAGwK4kjD/6vRost32kQkpdyRFkl6gFPzKg/iZdEbo7V1tj6KYhfm/H+vacgYCI3oG0tbajEHiyVV5k/X9gxdOqLj6YS3AIQc02O1FcPNae6cYTFgK11aImGBqyhGD0GfGdIxFKxnbd2xACLvkrnHFv4q97xCXwrfeS4+kY+j1JSxYLIdzAQ8A5QDmwRAjxppRyreOwbcBpUsoDQoiZwKPAccmySeMuGIJbeBGtNUCcNeLJooMQxOkRVG+xN8uoXGvF1FvVYB5P1VDuIEcrA6Fm3c7duV74qgpzXP+quq1DQ07caSpBGq3NRCSPwJOphED3Aqpab2/bmJGvYt2lE2HFM6p5nDtdfTZ5ZcpLiFcIdGjIGUoqm6xKUPtiwjDaZioGw0EgmVVDM4DNUsqtAEKI54FLgaAQSCk/dRz/GTCMg4DLmi2mNXXSS/9gEEwWWzPYeIXg4z+rUM2AEVZnyHJ1f+l4tXmHrz16f5ymahh4pNVb3qW2RcwsUKtaq7cqIdn2kRqg9YKzSB4BqCqfqEJQGxqiAeURBLyw9QN1u2qDFRvPt6uXpt8Eb9+lFn8VDLc3U9+zvPPSUY1+3fQ8O5TUj7tHGgzdIZl+5FDAuft1uXVfNL4BvB3pASHEzUKIpUKIpVVVVd02TFiljpktnbRQPhgEk8VWvD2ePQnq98DK5+GYr6mSwsq1dn5gkNVzPtqiMimtbRqLVSnnqNPs/IDusbP1AxUuCnjVjl9geQQRhCB3cOyqoUg5AlAN1FxpSgic+xoDTLlaCUb1ZrvvTnBgj6N0FKzVu+74PQiDIYVJphBEyuhFrI0UQpyBEoKISxillI9KKadLKaeXlibYcMqJFYbJaq3s5MCDQHszIKx4O52vCgbYs0IN0lOuUbP51jp7ha/e6zZaeMjbrEJIutb9a6/Daf+rrheNUg3hPn9GlSi6PKo5Haj7w5PF0HElsJPwAR5Cl/dPvFj11m+qChWMzALVchiUxwO2xxTvwO5yq/9zRpzCYTCkMMkUgnJguOP2MKBDkboQYjLwD+BSKWV1+ONJIW8wAQQ5rX0gNORtDu2FE0+yWC8Iyx2ohABg0ztqBqz7wEcTglgtmPWmLJvfUSWWw2eoEFFLLWyZb5c5OikYrpLF7WEloYGAei8dcgSWEOQPg8PPV7X+ez7veNz0b1g2WTmcoEfQhRl+QRzlmAaDIak5giXAOCHEKGA3cA0QsquFEOIw4FXgeinlxiTaEorbwwFRSE57H/AIvM3WXqiZaoereHIEWgiyi+1Qyd4VanDV/eJ1JU75UuUl6AFYr+qNtOjJueJ17NkqBPXBb1Q+or0RTrij43NKx6N6Fm1QW/pp2hvU/dGEYNSptmg17+943JCp8LU37XPqBK+nC0Jw1s/thXAGgyEqSfMIpJQ+4A5gLrAOeFFKuUYIcasQ4lbrsJ8BxcDDQogVQoilybInnGpXMXnt+zs/MBms+ze8Z7XnbW+2E6CZ+fELQVqmEpDsIrviKH+IvbCo5YCq0f/nuWqHL02TFpEIQpA/zA7/jD1LDdZI+ORBtRVhpC0C9YYiemtITaQ+Q2C3AB51SmjdfKTtAkefZq9K7mpoCNSGI+FbKBoMhg4ktehYSjlHSnm4lHKMlPJX1n2zpJSzrOvflFIOkFJOtf6mJ9MeJzXuEgp9veQRrHweFs1S173N9iw3syC+ZHFzjfIGdDWMHozDhaBmm1qtvPJ5e/P5oEcQoR+OO03F5Aceqc41dJplm1SbiESiaLQSj6p1ofc71wY4GX4cTPkKjL9ADeqFh0U+Lpy8BITAYDDERcquPqlNK6HQ10seQV25CrW0NaryTB0uyeiCR+DcMlDnCQqGqSQvQgmB3j+3qRI2v2s/F6K3Sp75O7jwD+p6WjqMO1uFZ6KtxnV71Mw+mkcQPtPPKVYtEvT9OjzUmRB4MuGiB+Do62IfZzAYukzqdR+1qE8rJVc2hoZmDha65r+p0koW69BQQfxCkBVBCPKHqJWlmQWq+kgLQVaRWqA1/nyVLHZ5oidRwzfpvuIxtYtarLYOpRNgd1hUL1poKJySw9VmK50dB7E32zEYDAmTsh5BQ7pVhhqtT06yaG+2wzMNVrWNMzQUT9VQS01oq+MhU9WlrrDJGmB5BNvVCuIpX1Htl5uqrTUEJfH16wG1925nQjlwotrtzNmSQm+03tkAH69HYDAYkkbqCkGGlWCtWh/7QCfNNdE3YYkXvfALVNmlN8FksVMIBh0JtyyAceeq21oIarbDgFFqx62AF5b/S4lBtLBQoujBfL/V/G7/Jnj/l2qDdR3bj4ZOQOf1wbYPBkOKkLJCsDvvKKophOVPxveElgPw4FT47OHuvXCdY7F1Y6VdPgrxJYv9PpWIDd/8pGyy3XAs6BFsU4vEBk+Cw2fCh/fDvjXRN1dPFGflUN1uePIy5XFc/1r0NhdBu6fALR+Z6h6DoRdJWSFIS8/gddfZsHGuvUF6LL54SW1qsufz7r1wrVMIKqzQkCUEWQOUMLQ1RH9+ay0go++Cpc/TsE+tA9AtGi76k2rgVrez5z2CAaPUuSvXwmu3KBuve1V14oyHsinxh6oMBkOPk7JCkJHm5vnAWarp2tLZKuyz6NHIvfylhOVPqOux9vWNh7py9ZrZJVZoqMkODQ22wiR7VoQ+x++zE8zBqp8YfeezCtVG5kg1SINKJJ9vrSeItoNWorjTVNJ36eOwfQGc/5vIaw4MBkOfJGWrhjI8Lnb6BsCkmbDscfj8aZVIrVwLFz8QevDu5WrzlpyBqhFatH1946GuXMXDc0rU9YDPThbrLQvLl6gFV4GAqvb5+E/Ka/nuitBVxdHQawlAhYY0U7+qwlFjz0rM9liUTlCf0dhz4Ojre/78BoMhaaS0R9DmCyBn3KwStANGqi6cy5+0d/zSLP+XCt+c9B3VsM0Z5+8qdbtUvX/uYLXgC2yPILtIVf7oBnLLn4A371Dlm9Kv4vtdFQIdGgIVfjnlByoU09OMPEkJ5SV/MWEeg+EQI4WFQL31tuEnw3c+h2+8Axf+Wa1cfefn9oEttbDqFTjyCnvGXt2N8FDdLtWoLXegHe7xOMozh01XHoGUsPoVFXK5+QPrdTd3TQg8OWrjmIPB9JvgB+tCdwYzGAyHBCkrBJketQlKmy9gtUlwqWqak78PG9+22y8vna3i+MfdDMVWb5z9m9RA/fiF8PED8b9oIKCqagqGqfbN0toqM0QIjlW5g70rYcenav/b7CI18O/fFF+OQLd+Lhp1cGfn7pSNNBoMhzQpKwRBj8AXtm/x8bepcMpbP1Aho0Wz1B63ZVNUXD+zUA3I1Zthx8fw+VPxv2jjPlXPXzDM3oMXQhdsaa/j/V8qoZh4kbpdPFZtT9lco2b6zr7+4WiPwBkWMhgMhigYIfAGQh/wZKmeNtWb1Yy/cR+c/D31mBCqr87+jaotAqjj9m+O70V1KEiHhoKv6RCCQZNUZ9HN76jjyqaq+4vH2aGhWGEhMEJgMBi6ROoKQTA05O/44JgzYMq1sG+VGohHnWY/pgfkTfPsWf3G/8b3ojrJXDhcJYs1zo6aael2MnfCRXZop3iMWndwYHvssBCofYTd6TD4qPjsMhgMKU3KCkGm5RG0hnsEmvN+pVa7nvuL0Dh7yTjVn2j7JzD5atXwLVwI6sojb9+ohaBgWHSPAGCo1Y1bh4VAhYZALWiLxyP4zudw1FWxjzMYDAZSeh2BI1kciewi+NobHe/Xm6kEvKq3jytNbdzSUqsWcgUC8K8LwdcOt30SOnuvK1etpjMLQvf/DReCY76mxOewE+z7tBA49xuORcGwzo8xGAwGUtgjyM1QGljX0t61J5Ycri7T8+Cw49W+u9Jv9/vf8r4K3zTsgX9/R1UXgbrc+qHdlyc9W4mCvu5k4ATlkbjc9n1FowHLM4lHCAwGgyFOUlYIxg5Ue/2ur4jR1ycSA0apTeLHnK42ZRk2XbWLWDpbeQNLZ6va/TN/qrak1K0pti9Q3TmP+bp9Lh0eCvcIIuHJVLkFMEJgMBh6lJQVgoIsD0MLs1i3t4tCkJaudtg64yfqtssNZ/8cdnwCc3+s1iAcfT2c/AOVY/jvPVC1ERY/pmL3k66wz6WTzfFuv6jDQ50liw0Gg6ELpKwQAEwsy2fd3jg2ggln8lUqfKM5+nrVnmLRIyoENO3raoHaZbNUKeiL18P6t9Rxzvr/3EEqV+D2dHyNSASFwHgEBoOh50hpITiiLI+tVY20eiOUkHYFIeDiB9VG7BMutOv388vg0ofU5jcyoNowOBk40Q73xINe2WyEwGAw9CApWzUEyiMISNi4r4HJwwq7d7KsAXD7YtVi2smEC+Csn6k9BpydQEG1szj+tvhfY9QpyisondD5sQaDwRAnKS8EAOv21ndfCCB624dTfhj5fncXwkKgPIhvL+u6XQaDwRCDpIaGhBDnCyE2CCE2CyHujvD4BCHEQiFEmxDizmTaEonDirLJSXd3PWFsMBgM/YikeQRCCDfwEHAOUA4sEUK8KaVc6zisBvgOcFmy7IiFyyUYPziPtYkkjA0Gg6GfkEyPYAawWUq5VUrZDjwPXOo8QEpZKaVcAniTaEdMdOWQ1Au/DAaDIcVIphAMBZxbeZVb9/UpJpbl09DqY3dtS2+bYjAYDL1CMoUg0o4oCU27hRA3CyGWCiGWVlVVddOsUKYOLwTg9meWs2zHgR49t8FgMBwKJFMIygFnkfwwYE8iJ5JSPiqlnC6lnF5a2rNbL04aWsADV0+lor6VKx/5lE827+/R8xsMBkNfJ5lCsAQYJ4QYJYRIB64B3kzi6yXMZUcP5f0fnk5BlodXlpf3tjkGg8FwUEla1ZCU0ieEuAOYC7iB2VLKNUKIW63HZwkhBgNLgXwgIIT4HnCElPKgl/HkZKRx1oSBvLt2H15/AI87pRddGwyGFCKpC8qklHOAOWH3zXJcr0CFjPoE500azKuf72bR1hpOHlfS2+YYDAbDQcFMex2cOq6UTI+LuWsqetsUg8FgOGgYIXCQle7mtMNLmbe2gkDArCswGAypgRGCMM47cjD76tv4/dwNzN9Qid8IgsFg6OcYIQjj7CMGMXZgLrM+3MKNjy/h3tdW9bZJBoPBkFRSuvtoJPIzPbz7g9Oob/Xyl3c38Y+Pt3Hi2BIumTKkt00zGAyGpGA8gijkZ3r40cwJTBsxgB+/uorbn1nO6ffP56mF25P2mtv3N/GvT7aZvkcGg+GgYoQgBh63iwevmUpWupsVu2rxuF3837/XsnhbDaA2tNnf2BY8vqKulbrmxPvn/WHeBv7v32vZUd3cbdsNBoMhXkxoqBOGDchm8Y/PQghBQ6uXS/72Cbc/u5wJg/NYsGk/uRlpfP+cw6lsaGX2x9sozc3gyW/MYOzAvC69Tl2Ll3lr9wGwYPN+RpbEuaG9wWAwdBPjEcSBEKp/Xl6mh1nXTaOx1ceaPfXcdd54jhkxgF/8Zy1//3ArFxxVRrtf8qVZC7vcwO6tL/bS7guQ5XHz8aaebaxnMBgMsTAeQRcZPziP+XeeTn5WGtnpafzP6ZKFW6rJz/IwaWgBO6qb+NrsxVz994V896xx3Hb6GNLiaFfxyvJyxg7MZdphA5izei8+fyCu5xkMBkN3MSNNAgwuyCQ7XWmoEIITx5YwaWgBACOKc3jz9pO5cHIZf3xnI+c98BGPfbSVDRUN7KppZtmOAzz8wWb+9M5GVu+uQ0rJlqpGlu04wJXHDOPkcSU0tPr4Yndd1Ndvbvfx/OKdtLT7Y9oppeSJT7ezq8bkHAwGQ3SMR5AECrI9PHjN0Zx/5GAeXbCVX81Zx6/mrAs5xiXgL+9tIiPNRZsvgEvA5UcPJT3NhRDw8ab9HHPYgIjn/+Vb63h20U4Wb6/hj1+eEgxdhbNoWw0/f3MNH22s4p83HNvj79PQc2yoaCAnw82wAdm9bUqPU9PUTpvPT1lBVm+bYoiCEYIkMvOoMmYeVcbmygbW7W2gxesnPzON6SOLcAnB3DUVbKlsZEBOOkeU5TO4IBOAI4fk88GGSk4ZV0JFXSsD8zMZUZxNSW4GH2/az7OLdjK6JIdXl+/m+FHFXHXs8Iiv/9RnOwB4b30lX5TXMnlYYcjjUkqufORTZowq5u6ZE7r03nz+AE3tfgqyPF3/YFKMQEBy+7PLufrY4Zw+fmCHx/0ByVf/sYiJZXk89Y3jesHC5HLXSyvZWdPMOz84rbdNMUTBCMFBYOzAvIhVRF+ZcVjE408eW8qsD7dw+cOfhtw/ZVgB++rbGF2Sw7+/fTI3P7WUn76xmoJsD+cdOTjk2Mr6VuauruArM4bz9uoKHnh3E7PDvIJPt1SzfGct6/Y2cOtpoynMTo/7Pf30jdX8Z+VeXrjlBI4Ykh/383qS2uZ22n0BSvMyonpFfYHNVY28vboClxARhWDRtmr2N7axZLuXNp+fjDR3L1iZHFq9fj7evJ82X4DKhlYG5mX2tkmGCJgcQR/kGyeP4icXTuTR66fxn2+fzOM3HMtd541HAjXN7fz+S5PJyUjjwWuOZuzAXG55ahn/+/JK6lrsNQzPLt6JLyC55dQxfOuU0by/vpL/rq4IWaz21MId5KS7afH6eX7JrgiWRGZ/YxuvLNtNQ5uPm/61hL11ie/3vHp3HVPumxdcmxEv/oDkggcXMOPX7zHp53OZ9eGWhG1INku2q/e2eHtNxMWCc1btBaDVG2Dlrui5oUORxdtqaPMFAFiyzWwF21cxQtAHKc3L4JunjObcIwczaWgBZ0wYyO1njOXNO05m7X3nMX1kEQAluRm89j8ncccZY3l5WTln/uEDnlq4nScXbufpz3Zw2uGljCzJ4esnjmTYgCxufXoZ5z+wgPnrK9lb18I76/Zx3QkjOHFMMU98uh2vPxCXfc8t2km7P8BD1x5DU5uPG2Yvob616wvpAgHJva+vpq7Fy+yPt3V4fGd1M+2+yDYt23GAPXWtfGXGYRx92ADun7uBtXsO+n5GcbF0uxoAqxraOiwW9Ack/11dwUljixECFm6p7tHX/nBjFVPum8eO6qYePW+8fLSxinS3i+x0N4u39ex7M/QcRggOMcJLStPTXNx53njevONkRpbk8NM31vCzN9aQ5nLxvbPHAZCbkca7PziN3185Gb+U3PivJdz0r6UEpOS640Zw00mj2FvXyo9fXcV3nvucv7y3iVavqkgKBGTILNbrD/DUZzs49fBSLpxcxqzrp7GlqpHbnl5Guy/Aoq3V3P3KF8x8cAGn/n4+++pbAVXp9OLSXSzeVkNjmw+AF5fuYuWuWiYMzuOddfuotI4FeGPFbk77w3wu/uvHrCrvOEv+7+oK0tNc3HvhRB669hgKszz8+LVVcbUPr2lqZ82e7s+811fUM+NX7wZn/NFYvK2GcQNz1fWwY1VYqJ1rZ4zgiLJ8Fm7t3p7ZTW0+Nu1rCN5+YclO6lq8PPJBdI9JSkllfSurd9fhi3MyEC8fbari2FEDmDZiAIu66PU5cdrl9Qd4d+2+qJMEQ9cxQtBPmDS0gJdvPYFXbjuBBf97BgvvOZOjHVVHmR43Vx07nP98+2SuPe4w1u2t54zxAxlelM2ZEwYybmAuLy0rZ/G2Gv70zkYu/MsCfvTyF0z/1bsc+6t3+dM7G/l0y34eeHcjlQ1t3HjiSABOGlvC766czCebqznt/vlc/ehnvLVqLyW56VTUt/Krt1S11E9eX83/vvwFV/19IUf931zO/OMH/OqtdcwYWcTDXz0Gf0Dy4lIVnnp37T5+8OJKJg8rpLalncse/oQXHaErKSVz11Rw6rgScjPSKMj28JOLJrJiVy33vr6K/66u4EBTe8TPSUrJLU8t5ZK/fcI71kpuzbb9TcxbUxF3r6c/zN1AZUMbv3xrXdTn7KltYXdtC1cfO5zCbA9LwgbDOav2kulxccaEUk4YXczynbVBEY7F5spG3l8fav/ynQe44C8LOO+Bj9i4r4GmNh/vr68k0+PileXl7K4NDeG1tPt5aP5mjv7FO8z49Xtc9NePufaxReypjR7q21ndzF0vreS9dfuiHqPZW9fCxn2NnDqulGNHFrFhX0PEFixSSpqsyYGUkicXbufGxxfTYHmZc9dUMO2X7wYnBLM/3sY3n1zK/XPXd2pDd6ltbg+ZoPRXTLK4HyGEYNqIopjHZHrc/Pryo7h0yhBGlao2Fi6X4PXbT8IvJfmZHj7cWMWPX13Ff77Yw5kTB9HU5uMv723iL++pc0wZXshph5cGz3nltGFUNbbx/OKd/PziI/jKjMPI9Lj58zsbefC9TRRme3h1+W5uOW00x40qYlV5Pav31JGR5uaXl09idGkuJ44p5rnFu6ht9vLEwu0cOSSfZ755HH6/5I7nlnPPa6soK8zklHGlrN5dz+7alqDHA3DZ1KF8sKGK55fs4rnFuxiQ7eE3V0zm3CMGsamykYIsD4MLMnlvXSVLth+gKCed259dzq8vPwopJfM3VPL26gqkhEumDOF3V04mK91Nuy/AE59uZ/6GSr5+4shgUv7znQd4d10lk4cVsHJXLXPXVHD6+IG8sWI3O6qbaWzz8fUTR7LGClcdN6qYz7bWhHgPK3fV8ury3Zw9cRDZ6WkcP7qYf3y8jUXbalhVXkt+loevnTCyw/9w3poKvvfCCprb/fz2iqO4+tjhzPpwK3+Yt4HB+ZlkpLmZ9eEWTh8/kFZvgD9fPYW7XvqCRz/cwn2XTgJgS1UjX31sERX1rZw1YSCnjCshIOGP8zYw88EF/OCcw7n62OHUt3qZu2YfVQ1t7G9s4+Vl5bT7Any8eT8njyuJmdhesFF5N6ceXkpdixcpYemOGs6aOCh4jM8f4PsvruTtVXs5ffxApJS8t74SgL9/uJXvnT2O3769nroWLz97czWP33AsD83fTJbHzWMLtnH6+IGcNDb+bWV9/gBul4iruGB3bQtffuRTWn0B3rj9JIYXxV/a++mW/by2fDc/vfgI8jM97K5t4bGPtnLa+FJOHVeK29X14oa6Zi8F2cmp0hOHWqfL6dOny6VLl/a2Gf2eQEDilxKPFYraUd3Ezppmhg3IZtiArOD9sWj1+jnnzx+yq6aFaSMG8MLNx0ddLf2fL/Zwx7Of4xJw5THDuPfCicEqpoZWL1+etZDdB1q4/8tTWLajhtmfbGfpvWczICe00qm53cfq3fX84j9rWbW7jrzMNBpafWR53Pz56in86Z2NeP2SF285gev+sYgNVhglLzON648foQTs3Y0MLcxiVEkOO2ua2VHdTHFOOtVN7Zw5YSBXHDOUZxftZH1FA/PvPJ0rHv4Er1/idgm27W8izSVwuQSluRlMPayQD9ZXsvLn5zL7k238es56Ft97FvUt6j3lZqbx8q0nMig/k/pWL1Pvm0ea2xUMe/z56ilcfvQw/AHJoq3VvL5iNy8uLWfKsALyszx8snk/x44sYtG2Gi6cXMZvrjiKB97ZxBMLt3PU0AL21Lbw2T1ncc+rq3h9xW5e/Z8TGVOay+UPf0pFXQt/v346M0bZk4dt+5v40StfsHhbDUU56dQ2t6OjbZkeF+cdOZjTDi/lBy+u5P9demREoQJYVV7HXS+vpKapnUU/Pos2X4Cj/m8uN508intmTgTUoPzdF1bw1hd7ueCowSzZfoDa5nZ+dP4EVpbX8c7aCm47bSx/fncjF08Zwr9X7uGIsnzWVdTzym0ncudLK2lu83P/lydz3Khi0tM6freklMFBv6apnQv/soCMNBdfnj6cq6YPpzQvI+T4jfsa2FffSn6mh++9sCLYVHJoYRZ/umoqD763kfoWH7NvOJasdFsEl2yv4Y0VuznniMFUNbRxz6tf4PVLzp44iAeumcqXZy1k3V41KRg2IIsnb5rB6NLcDva2ev2s3l3HEUPyg4tWARrbfJz354+44pih/PDc8RE/884QQiyTUk6P+JgRAkMy+XTLfv4wdwMPXnN0zBmVzx/gyYU7OGlsCeMHdyy13VPbosTAClucNLaYZ755fNTztfsCPLZgKzuqm5g2YgDPLlb5CIC/XXs0F00eQkOrly/K6xhamMVQh7h9uLGK2R9vo77Vi8fl4rbTx3DyuBJmf7yNv83fTEOrCmP85MKJfPOU0fx3dQW3Pr2MEcXZ3HfJkZw6rpTVe+r48qyFtPkCnDKuhKe+cRyf7zzA5Q9/yvGji1i9u55Mj5tXbjuBEcV2g8FrH/uMrVVN/OKySfzz460s31HL9SeMYM6qveytayU73c0VxwzlJxceQUBKrn1sEV+U13L3zAl865TRCCHYU9vCaffPx+uX3HDiSP7vkiPZXdvClx75lIZWH8eNKuK99ZX88+vTQ2bnGikln26p5unPdjCqJIcrjhnKmNLc4IAqpeTqv3/GjpomnrzpOJ5bvJP8LA83nTSS+hYf98/bwL9X7qEoJ51fXjaJC44qA+BLj3zK/sY2Hr9xBpkeF3e+tJJPNldz7wUT+dapo/H5A7T5AuRkpLGrppmz/vgh7f4AU4YV8Nr/nMSXZn3K8p21XH70UP589VRWlddx7T8+o6HVR15GGhPL8hk7KJdzjhjESWNKeGHpLh58dyNXHjOMu2dO4I7nPmfemgqmDCtk6Y4DZKS5+MqMw5g2YgB1LV7e+mIvC7faCe0sj5unvzmDhlZVHReQkG1V2V02dSh/ukot5ly6vYavzV5Ms2Ol/wmjizlpbDF/mLeRYQOy2FOrRNfrD/Dj11YxoiibV247kYr6Vu6fu4GmNh9tvgBLtx+gxetnSEEmP7v4CM47cjBCCH72xmqe+mwHL996QqdefzSMEBj6Be2+AJ9s2c976/ZxyZShITPZzmj1+rn3NVWh9Oj103Al4JqDEqyV5XVs2tfAFccMC85Cl+88wBFl+WR67Fmi9nLuPPdw7jhzHF5/gBm/epc2X4ALjirjf04f02FW2Or14xKC9DQXB5raufzhT9hR08wp40q5evpwzpwwMGQm2tLup6K+lVFh3WrvemklLy0r5+VbTwhWme2ta+HGx5ewvqIhKBCJsnBLNV957DMA0t0u2v0BctLdtFuhl2+ePJpbThtNXqYdypi3poLvv7CCdn+ATI8bn19y3yVHRl0Q+es563j0o608edMMTj28lPUV9fxmznp+fcVRDC3MCn5eH2/az/wNlWyoaGBDRQMNbT4yPS5avQFGFGezo7qZ40Ypr+mu88Zz+xlj2VzZyN8/3MJrn+/GZ7k8ZQWZfP3EkUwdXsi++laOHJIfXP/z4tJdrNldx+1njOX5Jbv40zsbufGkkRRmpfPYgq0MzMvgiZtmsGZPHfvq2/jKjMPwuAXff2EFr6/YExQ7UA0mb392OVdPH878DZU0tfkYWZKDlDBtxACmDi/ksQVbWV/RwGmHl3LJlCH88KWV3HjSSH5+ceL/MyMEBkMvsXp3HWNKc4ODd1VDG9npbnIy4kvP1Ta309zuZ0hh19oz7G9sY+6aCq6dcVhIPLy+1cu8Nfu4eEpZtxeu/fI/a3G5BN88ZRQHmrw8+tFWcjLc3H7GWAblR144VtnQyp/f2ciumhZ+cdmkDgLmxOcPsL6iIdjHKx7afQHeX7+Pd9dVcurhpVw8uYzf/XcDsz7cwpThhbxy6wkh4cnKBrWHSG5mGgPzMuOK3QcCklufXhZsGz9hcB6P33hsxBYabT4/q8rrmDZiQMj/4XvPf87rK/YwOD+Tf910LBMGhy7K9PkDPLFwB39+ZyONbT6GF2Ux93unhoSLuooRAoPBkLJIKXlvXSWThxf02MpmKSV76lopzkkP8QLjpb7Vyz8WbOOaY4fHFPl99a08+tFWLp06pEOLmK7Sa0IghDgfeBBwA/+QUv427HFhPX4B0AzcIKVcHuucRggMBoOh68QSgqStIxBCuIGHgJnAEcBXhBBHhB02Exhn/d0MPJIsewwGg8EQmWQuKJsBbJZSbpVStgPPA5eGHXMp8KRUfAYUCiHKkmiTwWAwGMJIphAMBZydzMqt+7p6DEKIm4UQS4UQS6uqzDaOBoPB0JMkUwgipd/DExLxHIOU8lEp5XQp5fTS0tIITzEYDAZDoiRTCMoBZ4HwMGBPAscYDAaDIYkkUwiWAOOEEKOEEOnANcCbYce8CXxNKI4H6qSUe5Nok8FgMBjCSFrTOSmlTwhxBzAXVT46W0q5Rghxq/X4LGAOqnR0M6p89MZk2WMwGAyGyCS1+6iUcg5qsHfeN8txXQK3J9MGg8FgMMTmkFtZLISoAnYk+PQSoHs7fyQfY2PPYGzsGYyN3aev2DdCShmx2uaQE4LuIIRYGm1lXV/B2NgzGBt7BmNj9+nr9oHZocxgMBhSHiMEBoPBkOKkmhA82tsGxIGxsWcwNvYMxsbu09ftS60cgcFgMBg6kmoegcFgMBjCMEJgMBgMKU7KCIEQ4nwhxAYhxGYhxN29bQ+AEGK4EGK+EGKdEGKNEOK71v1FQoh3hBCbrMsBvWynWwjxuRDiP33UvkIhxMtCiPXWZ3lCH7Tx+9b/eLUQ4jkhRGZv2yiEmC2EqBRCrHbcF9UmIcQ91u9ngxDivF608X7rf/2FEOI1IURhX7PR8didQggphCjpTRs7IyWEIM5NcnoDH/BDKeVE4Hjgdsuuu4H3pJTjgPes273Jd4F1jtt9zb4Hgf9KKScAU1C29hkbhRBDge8A06WUk1AtV67pAzb+Czg/7L6INlnfy2uAI63nPGz9rnrDxneASVLKycBG4J4+aCNCiOHAOcBOx329ZWNMUkIIiG+TnIOOlHKv3ppTStmAGsCGomx7wjrsCeCyXjEQEEIMAy4E/uG4uy/Zlw+cCvwTQErZLqWspQ/ZaJEGZAkh0oBsVJfdXrVRSvkRUBN2dzSbLgWel1K2SSm3ofqDzegNG6WU86SUPuvmZ6iuxX3KRos/A/9LaGv9XrGxM1JFCOLaAKc3EUKMBI4GFgGDdBdW63JgL5r2AOrLHHDc15fsGw1UAY9b4at/CCFy+pKNUsrdwB9QM8O9qC678/qSjQ6i2dRXf0M3AW9b1/uMjUKIS4DdUsqVYQ/1GRudpIoQxLUBTm8hhMgFXgG+J6Ws7217NEKIi4BKKeWy3rYlBmnAMcAjUsqjgSZ6P1QVghVnvxQYBQwBcoQQ1/WuVV2mz/2GhBD3osKrz+i7Ihx20G0UQmQD9wI/i/RwhPt6fSxKFSHosxvgCCE8KBF4Rkr5qnX3Pr13s3VZ2UvmnQRcIoTYjgqnnSmEeLoP2Qfqf1supVxk3X4ZJQx9ycazgW1SyioppRd4FTixj9moiWZTn/oNCSG+DlwEfFXai6H6io1jUKK/0vrtDAOWCyEG03dsDCFVhCCeTXIOOkIIgYptr5NS/snx0JvA163rXwfeONi2AUgp75FSDpNSjkR9Zu9LKa/rK/YBSCkrgF1CiPHWXWcBa+lDNqJCQscLIbKt//lZqHxQX7JRE82mN4FrhBAZQohRwDhgcS/YhxDifOBHwCVSymbHQ33CRinlKinlQCnlSOu3Uw4cY31X+4SNHZBSpsQfagOcjcAW4N7etsey6WSUW/gFsML6uwAoRlVsbLIui/qAracD/7Gu9yn7gKnAUutzfB0Y0AdtvA9YD6wGngIyettG4DlUzsKLGqy+EcsmVLhjC7ABmNmLNm5Gxdn1b2ZWX7Mx7PHtQElv2tjZn2kxYTAYDClOqoSGDAaDwRAFIwQGg8GQ4hghMBgMhhTHCIHBYDCkOEYIDAaDIcUxQmAwHESEEKfrLq4GQ1/BCIHBYDCkOEYIDIYICCGuE0IsFkKsEEL83dqToVEI8UchxHIhxHtCiFLr2KlCiM8c/fEHWPePFUK8K4RYaT1njHX6XGHvn/CMtdrYYOg1jBAYDGEIISYCVwMnSSmnAn7gq0AOsFxKeQzwIfBz6ylPAj+Sqj/+Ksf9zwAPSSmnoHoL7bXuPxr4HmpvjNGonk4GQ6+R1tsGGAx9kLOAacASa7KehWq+FgBesI55GnhVCFEAFEopP7TufwJ4SQiRBwyVUr4GIKVsBbDOt1hKWW7dXgGMBD5O+rsyGKJghMBg6IgAnpBS3hNypxA/DTsuVn+WWOGeNsd1P+Z3aOhlTGjIYOjIe8CXhBADIbiP7wjU7+VL1jHXAh9LKeuAA0KIU6z7rwc+lGpfiXIhxGXWOTKsPvUGQ5/DzEQMhjCklGuFED8B5gkhXKiukrejNr05UgixDKhD5RFAtWueZQ30W4EbrfuvB/4uhPh/1jm+fBDfhsEQN6b7qMEQJ0KIRillbm/bYTD0NCY0ZDAYDCmO8QgMBoMhxTEegcFgMKQ4RggMBoMhxTFCYDAYDCmOEQKDwWBIcYwQGAwGQ4rz/wFVmiWzBW7ChQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = StandardScaler()\n",
    "a.fit(x)\n",
    "X_standardized = a.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.874674e-17</td>\n",
       "      <td>5.110891e-17</td>\n",
       "      <td>-9.019220e-17</td>\n",
       "      <td>2.594099e-16</td>\n",
       "      <td>6.442300e-17</td>\n",
       "      <td>-8.718579e-17</td>\n",
       "      <td>-7.816657e-17</td>\n",
       "      <td>6.485249e-17</td>\n",
       "      <td>4.724353e-18</td>\n",
       "      <td>-4.790924e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>7.179943e-16</td>\n",
       "      <td>-1.933764e-16</td>\n",
       "      <td>-2.260174e-17</td>\n",
       "      <td>1.352883e-17</td>\n",
       "      <td>1.169277e-16</td>\n",
       "      <td>2.265542e-16</td>\n",
       "      <td>-2.596515e-16</td>\n",
       "      <td>1.443075e-16</td>\n",
       "      <td>6.253326e-16</td>\n",
       "      <td>4.024290e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.317959e+00</td>\n",
       "      <td>-1.423121e+00</td>\n",
       "      <td>-2.755520e+00</td>\n",
       "      <td>-2.134531e+00</td>\n",
       "      <td>-2.119754e+00</td>\n",
       "      <td>-2.133725e+00</td>\n",
       "      <td>-2.036890e+00</td>\n",
       "      <td>-1.713964e+00</td>\n",
       "      <td>-2.004018e+00</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.089076e+00</td>\n",
       "      <td>-9.031536e-01</td>\n",
       "      <td>-5.025653e-01</td>\n",
       "      <td>-8.010724e-01</td>\n",
       "      <td>-7.605602e-01</td>\n",
       "      <td>-6.928003e-01</td>\n",
       "      <td>-7.181571e-01</td>\n",
       "      <td>-7.060079e-01</td>\n",
       "      <td>-7.499909e-01</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.533922e-02</td>\n",
       "      <td>1.367805e-01</td>\n",
       "      <td>1.039993e-01</td>\n",
       "      <td>1.234588e-01</td>\n",
       "      <td>1.959092e-01</td>\n",
       "      <td>-4.438437e-02</td>\n",
       "      <td>4.755898e-02</td>\n",
       "      <td>-1.390326e-01</td>\n",
       "      <td>2.425585e-03</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.199754e+00</td>\n",
       "      <td>6.567476e-01</td>\n",
       "      <td>6.672378e-01</td>\n",
       "      <td>8.168572e-01</td>\n",
       "      <td>7.999952e-01</td>\n",
       "      <td>6.400547e-01</td>\n",
       "      <td>7.494654e-01</td>\n",
       "      <td>5.539372e-01</td>\n",
       "      <td>5.040366e-01</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.199754e+00</td>\n",
       "      <td>1.696682e+00</td>\n",
       "      <td>1.793715e+00</td>\n",
       "      <td>1.670271e+00</td>\n",
       "      <td>1.538322e+00</td>\n",
       "      <td>2.117002e+00</td>\n",
       "      <td>2.025659e+00</td>\n",
       "      <td>2.947833e+00</td>\n",
       "      <td>3.012092e+00</td>\n",
       "      <td>1.354679e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.512952e+00</td>\n",
       "      <td>4.984977e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>3.893103e+00</td>\n",
       "      <td>5.423261e+00</td>\n",
       "      <td>2.928152e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>2.271563e+01</td>\n",
       "      <td>5.785038e+00</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -4.874674e-17  5.110891e-17 -9.019220e-17  2.594099e-16  6.442300e-17   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.317959e+00 -1.423121e+00 -2.755520e+00 -2.134531e+00 -2.119754e+00   \n",
       "25%   -1.089076e+00 -9.031536e-01 -5.025653e-01 -8.010724e-01 -7.605602e-01   \n",
       "50%    5.533922e-02  1.367805e-01  1.039993e-01  1.234588e-01  1.959092e-01   \n",
       "75%    1.199754e+00  6.567476e-01  6.672378e-01  8.168572e-01  7.999952e-01   \n",
       "max    1.199754e+00  1.696682e+00  1.793715e+00  1.670271e+00  1.538322e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -8.718579e-17 -7.816657e-17  6.485249e-17  4.724353e-18 -4.790924e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -2.133725e+00 -2.036890e+00 -1.713964e+00 -2.004018e+00 -1.100649e-01   \n",
       "25%   -6.928003e-01 -7.181571e-01 -7.060079e-01 -7.499909e-01 -1.100649e-01   \n",
       "50%   -4.438437e-02  4.755898e-02 -1.390326e-01  2.425585e-03 -1.100649e-01   \n",
       "75%    6.400547e-01  7.494654e-01  5.539372e-01  5.040366e-01 -1.100649e-01   \n",
       "max    2.117002e+00  2.025659e+00  2.947833e+00  3.012092e+00  1.354679e+01   \n",
       "\n",
       "       ...            20            21            22            23  \\\n",
       "count  ...  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   ...  7.179943e-16 -1.933764e-16 -2.260174e-17  1.352883e-17   \n",
       "std    ...  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "25%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "50%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "75%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "max    ...  7.512952e+00  4.984977e+00  1.604681e+01  3.893103e+00   \n",
       "\n",
       "                 24            25            26            27            28  \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   1.169277e-16  2.265542e-16 -2.596515e-16  1.443075e-16  6.253326e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "25%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "50%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "75%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "max    5.423261e+00  2.928152e+00  1.604681e+01  2.271563e+01  5.785038e+00   \n",
       "\n",
       "                 29  \n",
       "count  5.170000e+02  \n",
       "mean   4.024290e-16  \n",
       "std    1.000969e+00  \n",
       "min   -7.060812e-01  \n",
       "25%   -7.060812e-01  \n",
       "50%   -7.060812e-01  \n",
       "75%    1.416268e+00  \n",
       "max    1.416268e+00  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_standardized).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuaral Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjadh\\AppData\\Local\\Temp\\ipykernel_27296\\1787105156.py:10: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
      "C:\\Users\\tjadh\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 1/5; 1/9] END .....batch_size=10, epochs=10;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 2/5; 1/9] END .....batch_size=10, epochs=10;, score=0.962 total time=   0.9s\n",
      "[CV 3/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 3/5; 1/9] END .....batch_size=10, epochs=10;, score=0.971 total time=   0.9s\n",
      "[CV 4/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 4/5; 1/9] END .....batch_size=10, epochs=10;, score=0.951 total time=   1.2s\n",
      "[CV 5/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 5/5; 1/9] END .....batch_size=10, epochs=10;, score=0.913 total time=   1.1s\n",
      "[CV 1/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 1/5; 2/9] END .....batch_size=10, epochs=50;, score=1.000 total time=   2.4s\n",
      "[CV 2/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 2/5; 2/9] END .....batch_size=10, epochs=50;, score=0.952 total time=   2.7s\n",
      "[CV 3/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 3/5; 2/9] END .....batch_size=10, epochs=50;, score=0.971 total time=   2.5s\n",
      "[CV 4/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 4/5; 2/9] END .....batch_size=10, epochs=50;, score=0.942 total time=   2.2s\n",
      "[CV 5/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 5/5; 2/9] END .....batch_size=10, epochs=50;, score=0.951 total time=   2.4s\n",
      "[CV 1/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 1/5; 3/9] END ....batch_size=10, epochs=100;, score=1.000 total time=   3.9s\n",
      "[CV 2/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 2/5; 3/9] END ....batch_size=10, epochs=100;, score=0.952 total time=   3.6s\n",
      "[CV 3/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 3/5; 3/9] END ....batch_size=10, epochs=100;, score=0.981 total time=   4.2s\n",
      "[CV 4/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 4/5; 3/9] END ....batch_size=10, epochs=100;, score=0.951 total time=   4.0s\n",
      "[CV 5/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 5/5; 3/9] END ....batch_size=10, epochs=100;, score=0.942 total time=   4.0s\n",
      "[CV 1/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 1/5; 4/9] END .....batch_size=20, epochs=10;, score=1.000 total time=   0.7s\n",
      "[CV 2/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 2/5; 4/9] END .....batch_size=20, epochs=10;, score=0.952 total time=   0.7s\n",
      "[CV 3/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 3/5; 4/9] END .....batch_size=20, epochs=10;, score=0.981 total time=   0.9s\n",
      "[CV 4/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 4/5; 4/9] END .....batch_size=20, epochs=10;, score=0.932 total time=   0.7s\n",
      "[CV 5/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 5/5; 4/9] END .....batch_size=20, epochs=10;, score=0.903 total time=   0.7s\n",
      "[CV 1/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 1/5; 5/9] END .....batch_size=20, epochs=50;, score=1.000 total time=   1.4s\n",
      "[CV 2/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 2/5; 5/9] END .....batch_size=20, epochs=50;, score=0.904 total time=   1.6s\n",
      "[CV 3/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 3/5; 5/9] END .....batch_size=20, epochs=50;, score=0.981 total time=   1.6s\n",
      "[CV 4/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 4/5; 5/9] END .....batch_size=20, epochs=50;, score=0.932 total time=   1.7s\n",
      "[CV 5/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 5/5; 5/9] END .....batch_size=20, epochs=50;, score=0.864 total time=   1.5s\n",
      "[CV 1/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 1/5; 6/9] END ....batch_size=20, epochs=100;, score=1.000 total time=   2.3s\n",
      "[CV 2/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 2/5; 6/9] END ....batch_size=20, epochs=100;, score=0.971 total time=   2.4s\n",
      "[CV 3/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 3/5; 6/9] END ....batch_size=20, epochs=100;, score=0.981 total time=   2.3s\n",
      "[CV 4/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 4/5; 6/9] END ....batch_size=20, epochs=100;, score=0.951 total time=   2.3s\n",
      "[CV 5/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 5/5; 6/9] END ....batch_size=20, epochs=100;, score=0.961 total time=   2.2s\n",
      "[CV 1/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 1/5; 7/9] END .....batch_size=40, epochs=10;, score=1.000 total time=   0.8s\n",
      "[CV 2/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 2/5; 7/9] END .....batch_size=40, epochs=10;, score=0.981 total time=   0.6s\n",
      "[CV 3/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 3/5; 7/9] END .....batch_size=40, epochs=10;, score=0.893 total time=   0.6s\n",
      "[CV 4/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x0000018A24AC11F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV 4/5; 7/9] END .....batch_size=40, epochs=10;, score=0.932 total time=   0.6s\n",
      "[CV 5/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000018A296A4CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV 5/5; 7/9] END .....batch_size=40, epochs=10;, score=0.932 total time=   0.6s\n",
      "[CV 1/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 1/5; 8/9] END .....batch_size=40, epochs=50;, score=1.000 total time=   1.2s\n",
      "[CV 2/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 2/5; 8/9] END .....batch_size=40, epochs=50;, score=0.952 total time=   1.2s\n",
      "[CV 3/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 3/5; 8/9] END .....batch_size=40, epochs=50;, score=0.981 total time=   1.0s\n",
      "[CV 4/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 4/5; 8/9] END .....batch_size=40, epochs=50;, score=0.942 total time=   1.2s\n",
      "[CV 5/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 5/5; 8/9] END .....batch_size=40, epochs=50;, score=0.913 total time=   1.0s\n",
      "[CV 1/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 1/5; 9/9] END ....batch_size=40, epochs=100;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 2/5; 9/9] END ....batch_size=40, epochs=100;, score=0.952 total time=   1.5s\n",
      "[CV 3/5; 9/9] START batch_size=40, epochs=100...................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/9] END ....batch_size=40, epochs=100;, score=0.951 total time=   1.5s\n",
      "[CV 4/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 4/5; 9/9] END ....batch_size=40, epochs=100;, score=0.971 total time=   1.5s\n",
      "[CV 5/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 5/5; 9/9] END ....batch_size=40, epochs=100;, score=0.932 total time=   1.7s\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=30, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\\\n",
    "    \n",
    "    adam=Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "# Define the grid search parameters\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9728715538978576, using {'batch_size': 20, 'epochs': 100}\n",
      "0.9592979788780213,0.028410807649881475 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.9632001399993897,0.020680512364966232 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.9651418924331665,0.021738578454537406 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.9534914135932923,0.0344030947081678 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.9361090421676636,0.04961032803998827 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.9728715538978576,0.01669740581032779 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.9476101517677307,0.03818166118890631 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.957374906539917,0.030437830893257366 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.9612583994865418,0.022936341415795723 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "def create_model(learning_rate,dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4,input_dim = 30,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjadh\\AppData\\Local\\Temp\\ipykernel_27296\\3207423715.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 1/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=1.000 total time=   0.6s\n",
      "[CV 2/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 2/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.750 total time=   0.6s\n",
      "[CV 3/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 3/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.524 total time=   0.7s\n",
      "[CV 4/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 4/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.680 total time=   0.9s\n",
      "[CV 5/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 5/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.835 total time=   0.6s\n",
      "[CV 1/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 1/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=1.000 total time=   0.6s\n",
      "[CV 2/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 2/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.933 total time=   0.6s\n",
      "[CV 3/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 3/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.951 total time=   0.6s\n",
      "[CV 4/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 4/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.951 total time=   0.8s\n",
      "[CV 5/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 5/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.942 total time=   0.6s\n",
      "[CV 1/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 1/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=1.000 total time=   0.6s\n",
      "[CV 2/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 2/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.942 total time=   0.7s\n",
      "[CV 3/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 3/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.874 total time=   1.1s\n",
      "[CV 4/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 4/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.961 total time=   0.6s\n",
      "[CV 5/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 5/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.903 total time=   0.6s\n",
      "[CV 1/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 1/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=1.000 total time=   0.7s\n",
      "[CV 2/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 2/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.750 total time=   1.0s\n",
      "[CV 3/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 3/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 4/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.680 total time=   0.7s\n",
      "[CV 5/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 5/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.699 total time=   0.8s\n",
      "[CV 1/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 1/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=1.000 total time=   0.7s\n",
      "[CV 2/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 2/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.952 total time=   1.0s\n",
      "[CV 3/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 3/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.913 total time=   0.7s\n",
      "[CV 4/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 4/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.932 total time=   0.7s\n",
      "[CV 5/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 5/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.932 total time=   0.7s\n",
      "[CV 1/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 1/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=1.000 total time=   0.8s\n",
      "[CV 2/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 2/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.952 total time=   0.6s\n",
      "[CV 3/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 3/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.961 total time=   0.7s\n",
      "[CV 4/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 4/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.951 total time=   0.6s\n",
      "[CV 5/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 5/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.913 total time=   0.6s\n",
      "[CV 1/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 1/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=1.000 total time=   0.8s\n",
      "[CV 2/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 2/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.750 total time=   0.6s\n",
      "[CV 3/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 3/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.524 total time=   0.6s\n",
      "[CV 4/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 4/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.680 total time=   0.6s\n",
      "[CV 5/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 5/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.699 total time=   1.0s\n",
      "[CV 1/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 1/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=1.000 total time=   0.7s\n",
      "[CV 2/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 2/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.971 total time=   0.9s\n",
      "[CV 3/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 3/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.971 total time=   0.9s\n",
      "[CV 4/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 4/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.932 total time=   1.0s\n",
      "[CV 5/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 5/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.932 total time=   0.7s\n",
      "[CV 1/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 1/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=1.000 total time=   0.7s\n",
      "[CV 2/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 2/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.962 total time=   0.8s\n",
      "[CV 3/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 3/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.971 total time=   1.0s\n",
      "[CV 4/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 4/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.942 total time=   0.8s\n",
      "[CV 5/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 5/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.903 total time=   0.7s\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9612210631370545, using {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.7577669858932495,0.15831793545589848 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.9554704904556275,0.023333538868459253 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.93603435754776,0.044123395854620356 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.9457244277000427,0.029848494790749885 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.9554331660270691,0.027856929806950478 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "0.9612210631370545,0.026072379964043952 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.9554144740104675,0.03227256381559228 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation_function,init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4,input_dim = 30,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjadh\\AppData\\Local\\Temp\\ipykernel_27296\\2157490907.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 1/5; 1/12] END activation_function=softmax, init=uniform;, score=0.000 total time=   0.7s\n",
      "[CV 2/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 2/5; 1/12] END activation_function=softmax, init=uniform;, score=0.250 total time=   0.9s\n",
      "[CV 3/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 3/5; 1/12] END activation_function=softmax, init=uniform;, score=0.524 total time=   0.7s\n",
      "[CV 4/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 4/5; 1/12] END activation_function=softmax, init=uniform;, score=0.680 total time=   0.7s\n",
      "[CV 5/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 5/5; 1/12] END activation_function=softmax, init=uniform;, score=0.301 total time=   0.7s\n",
      "[CV 1/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 1/5; 2/12] END activation_function=softmax, init=normal;, score=0.000 total time=   0.9s\n",
      "[CV 2/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 2/5; 2/12] END activation_function=softmax, init=normal;, score=0.750 total time=   1.0s\n",
      "[CV 3/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 3/5; 2/12] END activation_function=softmax, init=normal;, score=0.524 total time=   0.7s\n",
      "[CV 4/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 4/5; 2/12] END activation_function=softmax, init=normal;, score=0.680 total time=   0.8s\n",
      "[CV 5/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 5/5; 2/12] END activation_function=softmax, init=normal;, score=0.301 total time=   0.9s\n",
      "[CV 1/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 1/5; 3/12] END activation_function=softmax, init=zero;, score=1.000 total time=   0.7s\n",
      "[CV 2/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 2/5; 3/12] END activation_function=softmax, init=zero;, score=0.750 total time=   0.7s\n",
      "[CV 3/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 3/5; 3/12] END activation_function=softmax, init=zero;, score=0.524 total time=   0.6s\n",
      "[CV 4/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 4/5; 3/12] END activation_function=softmax, init=zero;, score=0.680 total time=   0.6s\n",
      "[CV 5/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 5/5; 3/12] END activation_function=softmax, init=zero;, score=0.699 total time=   0.9s\n",
      "[CV 1/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 1/5; 4/12] END activation_function=relu, init=uniform;, score=1.000 total time=   0.6s\n",
      "[CV 2/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 2/5; 4/12] END activation_function=relu, init=uniform;, score=0.750 total time=   0.6s\n",
      "[CV 3/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 3/5; 4/12] END activation_function=relu, init=uniform;, score=0.524 total time=   0.6s\n",
      "[CV 4/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 4/5; 4/12] END activation_function=relu, init=uniform;, score=0.680 total time=   0.8s\n",
      "[CV 5/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 5/5; 4/12] END activation_function=relu, init=uniform;, score=0.864 total time=   0.6s\n",
      "[CV 1/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 1/5; 5/12] END activation_function=relu, init=normal;, score=1.000 total time=   0.6s\n",
      "[CV 2/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 2/5; 5/12] END activation_function=relu, init=normal;, score=0.750 total time=   0.6s\n",
      "[CV 3/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 3/5; 5/12] END activation_function=relu, init=normal;, score=0.524 total time=   0.9s\n",
      "[CV 4/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 4/5; 5/12] END activation_function=relu, init=normal;, score=0.680 total time=   0.7s\n",
      "[CV 5/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 5/5; 5/12] END activation_function=relu, init=normal;, score=0.699 total time=   0.9s\n",
      "[CV 1/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 1/5; 6/12] END activation_function=relu, init=zero;, score=1.000 total time=   0.7s\n",
      "[CV 2/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 2/5; 6/12] END activation_function=relu, init=zero;, score=0.750 total time=   0.9s\n",
      "[CV 3/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 3/5; 6/12] END activation_function=relu, init=zero;, score=0.524 total time=   1.1s\n",
      "[CV 4/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 4/5; 6/12] END activation_function=relu, init=zero;, score=0.680 total time=   0.7s\n",
      "[CV 5/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 5/5; 6/12] END activation_function=relu, init=zero;, score=0.699 total time=   0.6s\n",
      "[CV 1/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 1/5; 7/12] END activation_function=tanh, init=uniform;, score=1.000 total time=   0.6s\n",
      "[CV 2/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 2/5; 7/12] END activation_function=tanh, init=uniform;, score=0.817 total time=   0.8s\n",
      "[CV 3/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 3/5; 7/12] END activation_function=tanh, init=uniform;, score=0.777 total time=   0.7s\n",
      "[CV 4/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 4/5; 7/12] END activation_function=tanh, init=uniform;, score=0.825 total time=   0.8s\n",
      "[CV 5/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 5/5; 7/12] END activation_function=tanh, init=uniform;, score=0.845 total time=   0.7s\n",
      "[CV 1/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 1/5; 8/12] END activation_function=tanh, init=normal;, score=1.000 total time=   0.9s\n",
      "[CV 2/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 2/5; 8/12] END activation_function=tanh, init=normal;, score=0.788 total time=   0.7s\n",
      "[CV 3/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 3/5; 8/12] END activation_function=tanh, init=normal;, score=0.835 total time=   0.7s\n",
      "[CV 4/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 4/5; 8/12] END activation_function=tanh, init=normal;, score=0.854 total time=   0.7s\n",
      "[CV 5/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 5/5; 8/12] END activation_function=tanh, init=normal;, score=0.757 total time=   0.7s\n",
      "[CV 1/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 1/5; 9/12] END activation_function=tanh, init=zero;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 2/5; 9/12] END activation_function=tanh, init=zero;, score=0.750 total time=   0.7s\n",
      "[CV 3/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 3/5; 9/12] END activation_function=tanh, init=zero;, score=0.524 total time=   0.7s\n",
      "[CV 4/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 4/5; 9/12] END activation_function=tanh, init=zero;, score=0.680 total time=   0.7s\n",
      "[CV 5/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 5/5; 9/12] END activation_function=tanh, init=zero;, score=0.699 total time=   0.8s\n",
      "[CV 1/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 1/5; 10/12] END activation_function=linear, init=uniform;, score=0.981 total time=   0.6s\n",
      "[CV 2/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 2/5; 10/12] END activation_function=linear, init=uniform;, score=0.817 total time=   0.6s\n",
      "[CV 3/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 10/12] END activation_function=linear, init=uniform;, score=0.757 total time=   0.6s\n",
      "[CV 4/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 4/5; 10/12] END activation_function=linear, init=uniform;, score=0.864 total time=   0.7s\n",
      "[CV 5/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 5/5; 10/12] END activation_function=linear, init=uniform;, score=0.845 total time=   0.8s\n",
      "[CV 1/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 1/5; 11/12] END activation_function=linear, init=normal;, score=0.990 total time=   0.6s\n",
      "[CV 2/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 2/5; 11/12] END activation_function=linear, init=normal;, score=0.817 total time=   0.6s\n",
      "[CV 3/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 3/5; 11/12] END activation_function=linear, init=normal;, score=0.680 total time=   0.6s\n",
      "[CV 4/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 4/5; 11/12] END activation_function=linear, init=normal;, score=0.845 total time=   0.8s\n",
      "[CV 5/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 5/5; 11/12] END activation_function=linear, init=normal;, score=0.767 total time=   0.7s\n",
      "[CV 1/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 1/5; 12/12] END activation_function=linear, init=zero;, score=1.000 total time=   0.6s\n",
      "[CV 2/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 2/5; 12/12] END activation_function=linear, init=zero;, score=0.750 total time=   0.6s\n",
      "[CV 3/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 3/5; 12/12] END activation_function=linear, init=zero;, score=0.524 total time=   0.7s\n",
      "[CV 4/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 4/5; 12/12] END activation_function=linear, init=zero;, score=0.680 total time=   1.0s\n",
      "[CV 5/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 5/5; 12/12] END activation_function=linear, init=zero;, score=0.699 total time=   0.7s\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids = dict(activation_function = activation_function,init = init)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.852819275856018, using {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.35097087025642393,0.23405710410063527 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
      "0.45097087025642396,0.27310905134889035 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
      "0.7635922312736512,0.16155351939420937 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'zero'}\n",
      "0.8527819275856018,0.07686945171329793 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
      "0.8470126986503601,0.08376707892022199 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
      "0.852819275856018,0.07342075906507944 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.8197908997535706,0.1021420633639994 with: {'activation_function': 'linear', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 30,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjadh\\AppData\\Local\\Temp\\ipykernel_27296\\1166029089.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 1/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.981 total time=   0.7s\n",
      "[CV 2/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 2/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.750 total time=   0.9s\n",
      "[CV 3/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 3/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.592 total time=   0.7s\n",
      "[CV 4/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 4/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.767 total time=   0.7s\n",
      "[CV 5/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 5/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.689 total time=   0.8s\n",
      "[CV 1/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 1/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.990 total time=   1.0s\n",
      "[CV 2/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 2/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.750 total time=   0.8s\n",
      "[CV 3/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 3/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.592 total time=   0.6s\n",
      "[CV 4/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 4/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.786 total time=   0.6s\n",
      "[CV 5/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 5/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.709 total time=   0.6s\n",
      "[CV 1/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 1/5; 3/9] END .........neuron1=4, neuron2=8;, score=1.000 total time=   0.8s\n",
      "[CV 2/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 2/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.750 total time=   0.6s\n",
      "[CV 3/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 3/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.709 total time=   0.6s\n",
      "[CV 4/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 4/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.748 total time=   0.6s\n",
      "[CV 5/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 5/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.738 total time=   0.6s\n",
      "[CV 1/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 1/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.990 total time=   0.9s\n",
      "[CV 2/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 2/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.798 total time=   0.6s\n",
      "[CV 3/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 3/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.699 total time=   0.6s\n",
      "[CV 4/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 4/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.806 total time=   0.6s\n",
      "[CV 5/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 5/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.806 total time=   0.8s\n",
      "[CV 1/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 1/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.990 total time=   0.6s\n",
      "[CV 2/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 2/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.808 total time=   0.6s\n",
      "[CV 3/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 3/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.748 total time=   0.6s\n",
      "[CV 4/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 4/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.786 total time=   0.6s\n",
      "[CV 5/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 5/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.816 total time=   0.9s\n",
      "[CV 1/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 1/5; 6/9] END .........neuron1=8, neuron2=8;, score=1.000 total time=   0.7s\n",
      "[CV 2/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 2/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.817 total time=   0.6s\n",
      "[CV 3/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 3/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.738 total time=   0.6s\n",
      "[CV 4/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 4/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.845 total time=   0.8s\n",
      "[CV 5/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 5/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.835 total time=   0.6s\n",
      "[CV 1/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 1/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.990 total time=   0.7s\n",
      "[CV 2/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 2/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.856 total time=   0.8s\n",
      "[CV 3/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 3/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.767 total time=   1.2s\n",
      "[CV 4/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 4/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.893 total time=   0.6s\n",
      "[CV 5/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 5/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.854 total time=   0.6s\n",
      "[CV 1/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 1/5; 8/9] END ........neuron1=16, neuron2=4;, score=1.000 total time=   0.7s\n",
      "[CV 2/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 2/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.817 total time=   0.8s\n",
      "[CV 3/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 3/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.854 total time=   0.6s\n",
      "[CV 4/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 4/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.913 total time=   0.6s\n",
      "[CV 5/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 5/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.874 total time=   0.6s\n",
      "[CV 1/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 1/5; 9/9] END ........neuron1=16, neuron2=8;, score=1.000 total time=   0.6s\n",
      "[CV 2/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 2/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.856 total time=   0.9s\n",
      "[CV 3/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 3/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.903 total time=   0.7s\n",
      "[CV 4/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 4/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.922 total time=   0.7s\n",
      "[CV 5/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 5/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.903 total time=   0.6s\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9167849063873291, using {'neuron1': 16, 'neuron2': 8}\n",
      "0.755862581729889,0.12801850948123095 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.7655526518821716,0.129995281193032 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.7888349533081055,0.10659734400903216 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.8198282361030579,0.09438982328165522 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.8295183062553406,0.08381347236956284 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.8469566941261292,0.08526653998512465 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.8721433877944946,0.07220215039690887 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.8916168808937073,0.062314169896068736 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.9167849063873291,0.04703891147111421 with: {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16,input_dim = 30,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'linear'))\n",
    "    \n",
    "    adam = Adam(lr = 0.01) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjadh\\AppData\\Local\\Temp\\ipykernel_27296\\1196441048.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step\n",
      "0.8878143133462283\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 100)\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "model.fit(X_standardized,y)\n",
    "\n",
    "# Predicting using trained model\n",
    "\n",
    "y_predict = model.predict(X_standardized)\n",
    "\n",
    "# Printing the metrics\n",
    "print(accuracy_score(y,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As we see the predicted area of the burned forest is about 98% "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                      *********************************************************************"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
